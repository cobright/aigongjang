import streamlit as st
import os
import json
import tempfile
import time

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì˜ˆì™¸ ì²˜ë¦¬ ---
# 1. Google GenAI (í…ìŠ¤íŠ¸ìš© - êµ¬ë²„ì „ SDK)
import google.generativeai as genai_old

# 2. Google GenAI (ì´ë¯¸ì§€ìš© - ì‹ ë²„ì „ SDK)
# pip install google-genai
try:
    from google import genai
    from google.genai import types
except ImportError:
    st.error("âŒ 'google-genai' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-genai")
    st.stop()

# 3. Google TTS
from google.cloud import texttospeech
from google.oauth2 import service_account

# 4. Pillow íŒ¨ì¹˜ (MoviePy 1.x í˜¸í™˜ì„±)
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

# 5. MoviePy
from moviepy.editor import *

# 6. .env ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# --- 1. í™˜ê²½ ë° UI ì„¤ì • ---
st.set_page_config(page_title="AI ì˜ìƒ ê³µì¥ (Google Edition)", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ AI ì˜ìƒ ê³µì¥ (Gemini 3 Pro Image)")

# --- [ì•ˆì „ì¥ì¹˜] Secrets ì¡°íšŒ í•¨ìˆ˜ ---
def get_secret(key_name):
    """st.secrets -> os.environ ìˆœì„œë¡œ í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        if key_name in st.secrets:
            return st.secrets[key_name]
    except (FileNotFoundError, AttributeError):
        pass
    return os.getenv(key_name)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì œì–´ê¸°")
    
    gemini_key = get_secret("GOOGLE_API_KEY")
    tts_key_path = get_secret("GOOGLE_APPLICATION_CREDENTIALS") # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    tts_key_json = get_secret("GOOGLE_APPLICATION_CREDENTIALS_JSON") # í´ë¼ìš°ë“œìš© JSON ë‚´ìš©
    
    # ìƒíƒœ í‘œì‹œ
    if gemini_key:
        st.success("âœ… Gemini API: Connected")
    else:
        st.error("âŒ Gemini API: Missing Key")
        
    if tts_key_path or tts_key_json:
        st.success("âœ… Google TTS: Connected")
    else:
        st.error("âŒ Google TTS: Missing Credentials")
    
    st.divider()
    
    st.subheader("ğŸ–¼ï¸ ìºë¦­í„° ì„¤ì •")
    default_char = "A young Korean office worker in a suit, simple clean lines, distinct facial features"
    character_desc = st.text_area("ì£¼ì¸ê³µ ì™¸ëª¨ ë¬˜ì‚¬", value=default_char, height=80)
    video_style = st.selectbox("í™”í’ (Style)", ["2D Webtoon Style", "Anime Style", "Realistic Cinematic", "Oil Painting"], index=0)
    
    num_scenes = st.slider("ìƒì„±í•  ì”¬(Scene) ê°œìˆ˜ (ê¶Œì¥: 4ê°œ ì´ìƒ)", 2, 6, 4)

# --- 2. í•µì‹¬ ëª¨ë“ˆ í•¨ìˆ˜ ---

def generate_script_json(topic, character_desc, num_scenes):
    """
    [Text] Gemini (Old SDK): 
    ê¸°ì¡´ì˜ ë‹¨ìˆœ ìƒì„± ë°©ì‹ì„ ë²„ë¦¬ê³ , 'Hook-Body-Conclusion' êµ¬ì¡°ë¥¼ ê°•ì œí•©ë‹ˆë‹¤.
    """
    if not gemini_key: return None
    
    try:
        genai_old.configure(api_key=gemini_key)
        
        # ìš”ì²­í•˜ì‹  ëŒ€ë¡œ 2.5 ë²„ì „ ì‚¬ìš© (ì£¼ì˜: 2.5ê°€ ì•„ì§ ë°°í¬ ì „ì´ë¼ë©´ 1.5ë‚˜ 2.0-flash-exp ì‚¬ìš©)
        model = genai_old.GenerativeModel('gemini-2.5-flash') 
        
        # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
        prompt = f"""
        You are an expert Content Creator for viral YouTube Shorts and TikTok.
        Your goal is to create a script for the topic: '{topic}'
        
        [STRUCTURE STRATEGY - MUST FOLLOW]
        Organize the {num_scenes} scenes strictly according to this flow:
        1. **HOOK (First 25% of scenes)**: Start with a question, a shocking fact, or a "Did you know?". Grab attention in 3 seconds.
        2. **BODY (Middle 50% of scenes)**: Explain the "How-to", "Why", or the core story. Fast-paced information.
        3. **OUTRO/CTA (Last 25% of scenes)**: A quick summary or punchline. End with a Call to Action (e.g., "Try this today!").

        [STRICT LANGUAGE RULES]
        1. "narrative": Must be in **KOREAN (í•œêµ­ì–´)**. Conversational, spoken style (êµ¬ì–´ì²´).
           - Do NOT use: "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ", "ì˜¤ëŠ˜ì€~". (Too formal)
           - USE: "ì´ê±° ì§„ì§œ ëŒ€ë°•ì…ë‹ˆë‹¤.", "í˜¹ì‹œ ì•Œê³  ê³„ì…¨ë‚˜ìš”?" (Engaging)
        2. "visual_prompt": Must be in **KOREAN (í•œêµ­ì–´)** (Best for image generation).
        
        [VISUAL DIRECTIVES]
        - Start every visual prompt with: "{character_desc}"
        - End every visual prompt with: "{video_style}, Cinematic lighting, 8k resolution"
        - **Constraint**: Describe the character DOING something active (eating, running, pointing, shocked face). NO boring standing poses.

        [OUTPUT FORMAT]
        Return ONLY valid JSON:
        {{
          "video_title": "A short, catchy viral title in Korean",
          "scenes": [
            {{ 
               "seq": 1, 
               "section": "HOOK",
               "narrative": "Korean voiceover text...", 
               "visual_prompt": "Detailed Korean image description..." 
            }},
            ... (Generate exactly {num_scenes} scenes)
          ]
        }}
        """
        
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        # ë§ˆí¬ë‹¤ìš´ ì œê±° (ì•ˆì „ì¥ì¹˜)
        if text.startswith("```json"):
            text = text[7:]
        if text.endswith("```"):
            text = text[:-3]
            
        return json.loads(text)
        
    except Exception as e:
        st.error(f"ğŸ§  Gemini ê¸°íš ì˜¤ë¥˜: {e}")
        return None

def generate_image_google(prompt, filename):
    """[Image] Gemini (New SDK): ì´ë¯¸ì§€ ìƒì„±"""
    if not gemini_key: return None
    
    output_path = os.path.join(tempfile.gettempdir(), filename)

    try:
        client = genai.Client(api_key=gemini_key)
        # ëª¨ë¸ ID í™•ì¸ í•„ìš” (imagen-3.0-generate-001 ë˜ëŠ” gemini-pro-vision ë“± ìƒí™©ì— ë§ê²Œ)
        # í˜„ì¬ ì½”ë“œì˜ gemini-3-pro-image-previewëŠ” Preview ê¶Œí•œì´ ìˆì–´ì•¼ ì‘ë™í•©ë‹ˆë‹¤.
        model_id = "gemini-3-pro-image-preview" # í˜¹ì€ "imagen-3.0-generate-001"
        
        # *ì°¸ê³ : Gemini 2.0 Flash ExpëŠ” ì´ë¯¸ì§€ ìƒì„±ì„ ì§€ì›í•˜ì§€ë§Œ, 
        # ì „ìš© Imagen ëª¨ë¸ì„ ì“´ë‹¤ë©´ ì½”ë“œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
        # ì—¬ê¸°ì„œëŠ” ì‘ì„±í•´ì£¼ì‹  ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
        
        contents = [types.Content(role="user", parts=[types.Part.from_text(text=prompt)])]
        generate_content_config = types.GenerateContentConfig(
            response_modalities=["IMAGE"],
            image_config=types.ImageConfig(image_size="1K"), # í˜¹ì€ "1024x1024" ë“± SDK ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„
        )

        response = client.models.generate_content(
            model=model_id,
            contents=contents,
            config=generate_content_config,
        )
        
        if response.candidates and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if part.inline_data and part.inline_data.data:
                    with open(output_path, "wb") as f:
                        f.write(part.inline_data.data)
                    return output_path
        
        st.warning("âš ï¸ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ëª¨ë¸ ì‘ë‹µ ì—†ìŒ).")
        return None

    except Exception as e:
        st.error(f"ğŸ¨ Google ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def generate_audio(text, filename):
    """[Voice] Google TTS"""
    output_path = os.path.join(tempfile.gettempdir(), filename)
    
    # ì¸ì¦ ì²˜ë¦¬ ë¡œì§ ë‹¨ìˆœí™” ë° ê°•í™”
    credentials = None
    
    try:
        # 1. Secret/Envì— JSON ë‚´ìš©ì´ í†µì§¸ë¡œ ìˆëŠ” ê²½ìš° (Streamlit Cloud ê¶Œì¥)
        if tts_key_json:
            try:
                creds_info = json.loads(tts_key_json, strict=False)
                credentials = service_account.Credentials.from_service_account_info(creds_info)
            except json.JSONDecodeError:
                st.error("TTS JSON í‚¤ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return None
        
        # 2. ë¡œì»¬ íŒŒì¼ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°
        elif tts_key_path and os.path.exists(tts_key_path):
            credentials = service_account.Credentials.from_service_account_file(tts_key_path)
            
        else:
            # í•˜ë“œì½”ë”©ëœ íŒŒì¼ëª…ì€ ì œê±°í•˜ê³  ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
            st.error("âŒ TTS ì¸ì¦ í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (.env ë˜ëŠ” secrets.toml í™•ì¸)")
            return None

        client = texttospeech.TextToSpeechClient(credentials=credentials)
        input_text = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Standard-C", ssml_gender=texttospeech.SsmlVoiceGender.MALE)
        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
        
        response = client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)
        with open(output_path, "wb") as out:
            out.write(response.audio_content)
        return output_path
        
    except Exception as e:
        st.error(f"ğŸ™ï¸ TTS ì˜¤ë¥˜: {e}")
        return None

def create_zoom_effect(clip, zoom_ratio=0.04):
    """Zoom Effect (OpenCV í•„ìš”)"""
    try:
        import cv2
    except ImportError:
        # OpenCV ì—†ìœ¼ë©´ íš¨ê³¼ ì—†ì´ ì›ë³¸ ë¦¬í„´
        return clip

    def effect(get_frame, t):
        img = get_frame(t)
        h, w = img.shape[:2]
        scale = 1 + zoom_ratio * t
        new_w, new_h = int(w * scale), int(h * scale)
        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        x = (new_w - w) // 2
        y = (new_h - h) // 2
        return img_resized[y:y+h, x:x+w]

    return clip.fl(effect)

# --- 3. ë©”ì¸ ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ìƒˆë¡œê³ ì¹¨ í•´ë„ ë°ì´í„° ìœ ì§€)
if "script_data" not in st.session_state:
    st.session_state["script_data"] = None
if "step" not in st.session_state:
    st.session_state["step"] = 1

st.divider()
st.header("Step 1. ê¸°íšì•ˆ ì‘ì„±")
topic = st.text_input("ì˜ìƒ ì£¼ì œ (Topic)", placeholder="ì˜ˆ: ì§‘ì—ì„œ ë§Œë“œëŠ” ìŠ¤íƒ€ë²…ìŠ¤ ëŒì²´ë¼ë–¼ ë ˆì‹œí”¼")

# [ë²„íŠ¼ 1] ê¸°íšì•ˆ ìƒì„±
if st.button("ğŸ’¡ 1. ê¸°íšì•ˆ(ëŒ€ë³¸) ìƒì„±í•˜ê¸°", type="primary", use_container_width=True):
    if not topic:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
        
    with st.spinner("ğŸ§  Geminiê°€ ê¸°ìŠ¹ì „ê²°(Hook-Body-CTA) êµ¬ì¡°ë¡œ ê¸°íš ì¤‘ì…ë‹ˆë‹¤..."):
        # 1ë‹¨ê³„ì—ì„œ ë§Œë“  êµ¬ì¡°í™”ëœ í•¨ìˆ˜ í˜¸ì¶œ
        script_data = generate_script_json(topic, character_desc, num_scenes)
        
        if script_data:
            st.session_state["script_data"] = script_data
            st.session_state["step"] = 2
            st.rerun() # í™”ë©´ ê°±ì‹ 
        else:
            st.error("ê¸°íšì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# [UI] ëŒ€ë³¸ ìˆ˜ì • ë° í™•ì • ë‹¨ê³„
if st.session_state["step"] >= 2 and st.session_state["script_data"]:
    st.divider()
    st.header("Step 2. ëŒ€ë³¸ ë° ì—°ì¶œ ìˆ˜ì •")
    st.info("ğŸ’¡ ì•„ë˜ ë‚´ìš©ì„ ìˆ˜ì •í•˜ë©´, ìˆ˜ì •ëœ ë‚´ìš©ëŒ€ë¡œ ì˜ìƒì´ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.")

    data = st.session_state["script_data"]
    scenes = data.get("scenes", [])
    
    # í¼(Form)ì„ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ë°ì´í„° ìˆ˜ì§‘
    with st.form("script_edit_form"):
        # íƒ€ì´í‹€ ìˆ˜ì •
        new_title = st.text_input("ì˜ìƒ ì œëª©", value=data.get("video_title", ""))
        
        edited_scenes = []
        for i, scene in enumerate(scenes):
            st.subheader(f"ğŸ¬ Scene {scene['seq']} ({scene.get('section', 'General')})")
            
            # ë ˆì´ì•„ì›ƒ 2ë‹¨ ë¶„ë¦¬ (ì™¼ìª½: ëŒ€ë³¸ / ì˜¤ë¥¸ìª½: ê·¸ë¦¼ ë¬˜ì‚¬)
            col1, col2 = st.columns(2)
            
            with col1:
                # keyë¥¼ ê³ ìœ í•˜ê²Œ ì§€ì •í•´ì•¼ í•¨
                new_narrative = st.text_area(
                    label="ğŸ—£ï¸ ë‚´ë ˆì´ì…˜ (í•œêµ­ì–´)", 
                    value=scene['narrative'], 
                    height=100,
                    key=f"narr_area_{i}"
                )
            
            with col2:
                new_visual = st.text_area(
                    label="ğŸ–¼ï¸ ê·¸ë¦¼ ë¬˜ì‚¬ (ì˜ì–´ ê¶Œì¥)", 
                    value=scene['visual_prompt'], 
                    height=100,
                    key=f"vis_area_{i}"
                )
            
            # ìˆ˜ì •ëœ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì„ ì¤€ë¹„ (ì‹¤ì œ ì—…ë°ì´íŠ¸ëŠ” ë²„íŠ¼ í´ë¦­ ì‹œ ì²˜ë¦¬)
            # ì—¬ê¸°ì„œëŠ” í¼ ë‚´ë¶€ë¼ UIë§Œ ë³´ì—¬ì£¼ê³ , ë°ì´í„° ì²˜ë¦¬ëŠ” ì•„ë˜ submit ë²„íŠ¼ ì´í›„ì— í•¨.
            
        # [ë²„íŠ¼ 2] ì˜ìƒ ìƒì„± ì‹œì‘
        generate_btn = st.form_submit_button("ğŸ¬ 2. ì´ ë‚´ìš©ìœ¼ë¡œ ì˜ìƒ ë§Œë“¤ê¸° (Start Generation)", type="primary", use_container_width=True)

    # í¼ ì œì¶œ ë²„íŠ¼ì´ ëˆŒë ¸ì„ ë•Œ ì‹¤í–‰
    if generate_btn:
        # ìˆ˜ì •ëœ ë°ì´í„° ìˆ˜ì§‘
        final_scenes = []
        for i, org_scene in enumerate(scenes):
            final_scenes.append({
                "seq": org_scene['seq'],
                "narrative": st.session_state[f"narr_area_{i}"],      # ìœ„ text_areaì˜ keyê°’ìœ¼ë¡œ ì½ì–´ì˜´
                "visual_prompt": st.session_state[f"vis_area_{i}"]   # ìœ„ text_areaì˜ keyê°’ìœ¼ë¡œ ì½ì–´ì˜´
            })
            
        # ë³¸ê²©ì ì¸ ìƒì„± ì‹œì‘
        status_box = st.status("ğŸ—ï¸ ì˜ìƒ ì œì‘ ê³µì¥ ê°€ë™ ì¤‘...", expanded=True)
        
        # Phase 2: Asset Generation
        status_box.write("ğŸ¨ Phase 2: ì´ë¯¸ì§€ ë° ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")
        progress_bar = st.progress(0)
        generated_clips = []
        
        for i, scene in enumerate(final_scenes):
            idx = scene['seq']
            status_box.write(f"  - Scene {idx} ì‘ì—… ì¤‘...")
            
            timestamp = int(time.time())
            img_name = f"img_{idx}_{timestamp}.png"
            aud_name = f"aud_{idx}_{timestamp}.mp3"
            
            # ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ë¡œ ì˜¤ë””ì˜¤/ì´ë¯¸ì§€ ìƒì„±
            aud_path = generate_audio(scene['narrative'], aud_name)
            img_path = generate_image_google(scene['visual_prompt'], img_name)
            
            if img_path and aud_path:
                try:
                    audio_clip = AudioFileClip(aud_path)
                    img_clip = ImageClip(img_path).set_duration(audio_clip.duration).resize(height=720)
                    video_clip = create_zoom_effect(img_clip) 
                    video_clip = video_clip.set_audio(audio_clip)
                    generated_clips.append(video_clip)
                except Exception as e:
                    st.warning(f"Scene {idx} í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            
            progress_bar.progress((i + 1) / len(final_scenes))

        # Phase 3: Final Rendering
        if generated_clips:
            status_box.write("ğŸ¬ Phase 3: ìµœì¢… í•©ì¹˜ê¸° ë° ë Œë”ë§...")
            try:
                final_video = concatenate_videoclips(generated_clips, method="compose")
                
                safe_title = "".join([c for c in new_title if c.isalnum()]).strip() or "output"
                output_path = os.path.join(tempfile.gettempdir(), f"{safe_title}_final.mp4")
                
                # í”„ë¦¬ì…‹ì„ ultrafastë¡œ í•˜ì—¬ ì†ë„ ìµœì í™”
                final_video.write_videofile(output_path, fps=24, codec='libx264', audio_codec='aac', preset='ultrafast')
                
                status_box.update(label="âœ… ì˜ìƒ ì™„ì„±!", state="complete", expanded=False)
                st.balloons()
                st.success(f"ğŸ‰ '{new_title}' ì˜ìƒì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.video(output_path)
                
            except Exception as e:
                st.error(f"ë Œë”ë§ ì˜¤ë¥˜: {e}")
        else:
            st.error("âŒ ìƒì„±ëœ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")