import streamlit as st
import os
import json
import requests
import fal_client
import google.generativeai as genai
from google.cloud import texttospeech
import tempfile

# ğŸ‘‡ [ì´ ë¶€ë¶„ ì¶”ê°€] Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ í˜¸í™˜ì„± íŒ¨ì¹˜
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS
# ğŸ‘† [ì—¬ê¸°ê¹Œì§€ ì¶”ê°€]

# ê·¸ ë‹¤ìŒ moviepyë¥¼ ë¶ˆëŸ¬ì™€ì•¼ ì—ëŸ¬ê°€ ì•ˆ ë‚©ë‹ˆë‹¤.
from moviepy.editor import *

# ë¡œì»¬ í™˜ê²½ìš© (.env íŒŒì¼ ë¡œë“œ)
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# --- 1. í™˜ê²½ ë° UI ì„¤ì • ---
st.set_page_config(page_title="AI ì˜ìƒ ê³µì¥ (Final)", page_icon="ğŸ­", layout="wide")
st.title("ğŸ­ AI ìœ íŠœë¸Œ í’€ìë™ ê³µì¥ (ì„¤ê³„ë„ ì™„ë²½ êµ¬í˜„)")

# ì‚¬ì´ë“œë°”: ì„¤ì • ë° ìºë¦­í„° ì•µì»¤ë§
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì œì–´ê¸°")
    
    # API í‚¤ ê²€ì¦
    api_status = {
        "Gemini (Brain)": "GOOGLE_API_KEY" in st.secrets or os.getenv("GOOGLE_API_KEY"),
        "Fal.ai (Visual)": "FAL_KEY" in st.secrets or os.getenv("FAL_KEY"),
        "Google TTS (Voice)": "GOOGLE_APPLICATION_CREDENTIALS_JSON" in st.secrets or os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    }
    for name, ready in api_status.items():
        if ready: st.success(f"{name}: ON")
        else: st.error(f"{name}: OFF")
    
    st.divider()
    
    # [ì„¤ê³„ë„ êµ¬í˜„] Consistency Injection (ì¼ê´€ì„± ì£¼ì…)
    st.subheader("ğŸ–¼ï¸ ìºë¦­í„° ì¼ê´€ì„± (Consistency)")
    default_char = "A young Korean office worker in a suit, simple clean lines, distinct facial features"
    character_desc = st.text_area("ì£¼ì¸ê³µ ì™¸ëª¨ ë¬˜ì‚¬ (Anchor)", value=default_char, height=80)
    video_style = st.selectbox("í™”í’ (Style)", ["2D Webtoon Style", "Anime Style", "Realistic Cinematic"], index=0)
    
    num_scenes = st.slider("ìƒì„±í•  ì”¬(Scene) ê°œìˆ˜", 1, 5, 3)

# --- 2. í•µì‹¬ ëª¨ë“ˆ í•¨ìˆ˜ ---

def get_api_key(key_name):
    if key_name in st.secrets: return st.secrets[key_name]
    return os.getenv(key_name)

def generate_script_json(topic, character_desc):
    """
    [Phase 1] Gemini: ê¸°íš ë° ëŒ€ë³¸ ì‘ì„± (ì–¸ì–´ ì„¤ì • ê°•í™”)
    """
    api_key = get_api_key("GOOGLE_API_KEY")
    if not api_key: return None
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # í”„ë¡¬í”„íŠ¸ì— 'ì–¸ì–´ ê·œì¹™(Language Rules)'ì„ ëª…í™•íˆ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.
        prompt = f"""
        Act as a professional YouTube content researcher and writer.
        Topic: '{topic}'
        
        [STRICT LANGUAGE RULES]
        1. "narrative": Must be in **KOREAN (í•œêµ­ì–´)** for the voiceover.
        2. "visual_prompt": Must be in **ENGLISH** for the image generator.
        
        [INSTRUCTION]
        1. FACT CHECK: Verify key facts about the topic.
        2. CHARACTER: You must include the character description in every visual prompt.
           If the provided 'character_desc' is in Korean, TRANSLATE it into English.
        3. STYLE: End every visual prompt with "{video_style}".
        
        [Ref: Character Description]
        "{character_desc}"
        
        Output ONLY valid JSON format:
        {{
          "video_title": "Catchy Title in Korean",
          "scenes": [
            {{ 
               "seq": 1, 
               "narrative": "í•œêµ­ì–´ ë‚´ë ˆì´ì…˜ ëŒ€ë³¸ (ì„±ìš°ìš©)", 
               "visual_prompt": "Detailed English description starting with translated character traits, describing [Action/Background], ending with {video_style}" 
            }},
            ... (Total {num_scenes} scenes)
          ]
        }}
        """
        
        response = model.generate_content(prompt)
        text = response.text.strip()
        # ë§ˆí¬ë‹¤ìš´ ì œê±°
        if text.startswith("```"):
            text = text.replace("```json", "").replace("```", "").strip()
            
        return json.loads(text)
    except Exception as e:
        st.error(f"ğŸ§  Gemini ê¸°íš ì˜¤ë¥˜: {e}")
        return None

def generate_image(prompt, filename):
    """
    [Phase 2] Nano Banana (Fal.ai): ì´ë¯¸ì§€ ìƒì„±
    """
    output_path = os.path.join(tempfile.gettempdir(), filename)
    os.environ["FAL_KEY"] = get_api_key("FAL_KEY")
    
    try:
        handler = fal_client.submit(
            "fal-ai/flux/dev",
            arguments={
                "prompt": prompt,
                "image_size": "landscape_16_9",
                "seed": 42, # [ì„¤ê³„ë„ êµ¬í˜„] Seed ê³ ì •ìœ¼ë¡œ ì¼ê´€ì„± í™•ë³´
                "num_inference_steps": 25
            }
        )
        image_url = handler.get()['images'][0]['url']
        with open(output_path, 'wb') as f:
            f.write(requests.get(image_url).content)
        return output_path
    except Exception as e:
        st.error(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def generate_audio(text, filename):
    """
    [Phase 2] Google TTS: ì˜¤ë””ì˜¤ ìƒì„±
    """
    output_path = os.path.join(tempfile.gettempdir(), filename)
    creds_json = get_api_key("GOOGLE_APPLICATION_CREDENTIALS_JSON")
    if not creds_json: return None
    
    try:
        from google.oauth2 import service_account
        creds_info = json.loads(creds_json, strict=False)
        credentials = service_account.Credentials.from_service_account_info(creds_info)
        client = texttospeech.TextToSpeechClient(credentials=credentials)

        input_text = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Standard-C", ssml_gender=texttospeech.SsmlVoiceGender.MALE)
        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
        
        response = client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)
        with open(output_path, "wb") as out:
            out.write(response.audio_content)
        return output_path
    except Exception as e:
        st.error(f"ğŸ™ï¸ TTS ì˜¤ë¥˜: {e}")
        return None

def create_zoom_effect(clip, zoom_ratio=0.04):
    """
    [Phase 3] Zoom Effect: ë°‹ë°‹í•œ ì •ì§€ ì´ë¯¸ì§€ë¥¼ ë™ì ìœ¼ë¡œ ë³€í™˜ (Ken Burns íš¨ê³¼)
    """
    def effect(get_frame, t):
        img = get_frame(t)
        h, w = img.shape[:2]
        # ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì¡°ê¸ˆì”© í™•ëŒ€ (Zoom In)
        scale = 1 + zoom_ratio * t
        
        # OpenCVë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ ìµœì í™”)
        import cv2
        new_w, new_h = int(w * scale), int(h * scale)
        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # ì¤‘ì•™ í¬ë¡­ (Center Crop)
        x = (new_w - w) // 2
        y = (new_h - h) // 2
        return img_resized[y:y+h, x:x+w]

    return clip.fl(effect)

# --- 3. ë©”ì¸ ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬ ---

topic = st.text_input("ì˜ìƒ ì£¼ì œ (Topic)", placeholder="ì˜ˆ: ë¹„íŠ¸ì½”ì¸ 1ì–µ ëŒíŒŒì˜ ì´ìœ ")

if st.button("ğŸš€ ì‹œìŠ¤í…œ ê°€ë™ (Start Process)", type="primary"):
    if not topic: st.stop()
    
    status_box = st.status("ğŸ—ï¸ ê³µì¥ ê°€ë™ ì¤‘...", expanded=True)
    
    # --- Phase 1: ê¸°íš ---
    status_box.write("ğŸ§  Phase 1: Geminiê°€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„¤ê³„ ì¤‘ì…ë‹ˆë‹¤...")
    script_data = generate_script_json(topic, character_desc)
    
    if not script_data:
        status_box.update(label="âŒ ê¸°íš ë‹¨ê³„ ì‹¤íŒ¨", state="error")
        st.stop()
        
    scenes = script_data.get("scenes", [])
    st.json(script_data) # ê¸°íšì•ˆ ì¶œë ¥
    
    # --- Phase 2: ìì‚° ìƒì„± ---
    status_box.write("ğŸ¨ Phase 2: ì´ë¯¸ì§€ì™€ ìŒì„±ì„ ë³‘ë ¬(ìˆœì°¨) ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
    progress_bar = st.progress(0)
    generated_clips = []
    
    for i, scene in enumerate(scenes):
        idx = scene['seq']
        
        # íŒŒì¼ëª… ìƒì„±
        img_name = f"img_{idx}.png"
        aud_name = f"aud_{idx}.mp3"
        
        # ìƒì„± (ì—ëŸ¬ ì‹œ í•´ë‹¹ ì”¬ ìŠ¤í‚µ)
        img_path = generate_image(scene['visual_prompt'], img_name)
        aud_path = generate_audio(scene['narrative'], aud_name)
        
        if img_path and aud_path:
            # í´ë¦½ ì¡°í•©
            try:
                audio_clip = AudioFileClip(aud_path)
                # [ì„¤ê³„ë„ êµ¬í˜„] ê¸°ë³¸ ì´ë¯¸ì§€ í´ë¦½ ìƒì„±
                img_clip = ImageClip(img_path).set_duration(audio_clip.duration).resize(height=720)
                
                # [ì„¤ê³„ë„ êµ¬í˜„] Zoom Effect ì ìš©! (ì •ì§€ í™”ë©´ íƒˆí”¼)
                # *ì£¼ì˜: Streamlit Cloud ì‚¬ì–‘ìƒ ë³µì¡í•˜ë©´ ëŠë ¤ì§ˆ ìˆ˜ ìˆì–´ ê°€ë³ê²Œ ì ìš©
                video_clip = create_zoom_effect(img_clip, zoom_ratio=0.04) 
                
                video_clip = video_clip.set_audio(audio_clip)
                generated_clips.append(video_clip)
                
                # ì¤‘ê°„ ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
                with st.expander(f"Scene {idx} ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    st.image(img_path, caption=f"Scene {idx}")
                    st.audio(aud_path)
                    
            except Exception as e:
                st.warning(f"Scene {idx} ì¡°ë¦½ ì¤‘ ì˜¤ë¥˜: {e}")
        
        progress_bar.progress((i + 1) / len(scenes))
        
    # --- Phase 3: ìµœì¢… ì¡°ë¦½ ---
    if generated_clips:
        status_box.write("ğŸ¬ Phase 3: FFmpeg ì—”ì§„ìœ¼ë¡œ ì˜ìƒì„ ë Œë”ë§ ì¤‘ì…ë‹ˆë‹¤...")
        try:
            # ì•ˆì „í•œ í•©ì¹˜ê¸°
            final_video = concatenate_videoclips(generated_clips, method="compose")
            
            # íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜
            safe_title = "".join([c for c in script_data['video_title'] if c.isalnum()]).strip() or "output"
            output_path = os.path.join(tempfile.gettempdir(), f"{safe_title}.mp4")
            
            # ë Œë”ë§ (ì†ë„ ìš°ì„ )
            final_video.write_videofile(
                output_path, 
                fps=24, 
                codec='libx264', 
                audio_codec='aac', 
                preset='ultrafast'
            )
            
            status_box.update(label="âœ… ëª¨ë“  ê³µì • ì™„ë£Œ!", state="complete", expanded=False)
            st.success("ğŸ‰ ì˜ìƒ ì™„ì„±!")
            
            st.video(output_path)
            with open(output_path, 'rb') as f:
                st.download_button("ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ", f, file_name=f"{safe_title}.mp4")
                
        except Exception as e:
            st.error(f"ë Œë”ë§ ì˜¤ë¥˜: {e}")
    else:
        st.error("âŒ ìƒì„±ëœ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")