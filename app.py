import streamlit as st
import os
import json
import tempfile
import time

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì˜ˆì™¸ ì²˜ë¦¬ ---
# 1. Google GenAI (í…ìŠ¤íŠ¸ìš© - êµ¬ë²„ì „ SDK)
import google.generativeai as genai_old

# 2. Google GenAI (ì´ë¯¸ì§€ìš© - ì‹ ë²„ì „ SDK)
# pip install google-genai
try:
    from google import genai
    from google.genai import types
except ImportError:
    st.error("âŒ 'google-genai' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-genai")
    st.stop()

# 3. Google TTS
from google.cloud import texttospeech
from google.oauth2 import service_account

# 4. Pillow íŒ¨ì¹˜ (MoviePy 1.x í˜¸í™˜ì„±)
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

# 5. MoviePy
from moviepy.editor import *

# 6. .env ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# --- 1. í™˜ê²½ ë° UI ì„¤ì • ---
st.set_page_config(page_title="AI ì˜ìƒ ê³µì¥ (Google Edition)", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ AI ì˜ìƒ ê³µì¥ (Gemini 3 Pro Image)")

# --- [ì•ˆì „ì¥ì¹˜] Secrets ì¡°íšŒ í•¨ìˆ˜ ---
def get_secret(key_name):
    """st.secrets -> os.environ ìˆœì„œë¡œ í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        if key_name in st.secrets:
            return st.secrets[key_name]
    except (FileNotFoundError, AttributeError):
        pass
    return os.getenv(key_name)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì œì–´ê¸°")
    
    gemini_key = get_secret("GOOGLE_API_KEY")
    tts_key_path = get_secret("GOOGLE_APPLICATION_CREDENTIALS") # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    tts_key_json = get_secret("GOOGLE_APPLICATION_CREDENTIALS_JSON") # í´ë¼ìš°ë“œìš© JSON ë‚´ìš©
    
    # ìƒíƒœ í‘œì‹œ
    if gemini_key:
        st.success("âœ… Gemini API: Connected")
    else:
        st.error("âŒ Gemini API: Missing Key")
        
    if tts_key_path or tts_key_json:
        st.success("âœ… Google TTS: Connected")
    else:
        st.error("âŒ Google TTS: Missing Credentials")
    
    st.divider()
    
    st.subheader("ğŸ–¼ï¸ ìºë¦­í„° ì„¤ì •")
    default_char = "A young Korean office worker in a suit, simple clean lines, distinct facial features"
    character_desc = st.text_area("ì£¼ì¸ê³µ ì™¸ëª¨ ë¬˜ì‚¬", value=default_char, height=80)
    video_style = st.selectbox("í™”í’ (Style)", ["2D Webtoon Style", "Anime Style", "Realistic Cinematic", "Oil Painting"], index=0)
    
    num_scenes = st.slider("ìƒì„±í•  ì”¬(Scene) ê°œìˆ˜", 1, 5, 2)

# --- 2. í•µì‹¬ ëª¨ë“ˆ í•¨ìˆ˜ ---

def generate_script_json(topic, character_desc):
    """[Text] Gemini (Old SDK): ê¸°íš ë° ëŒ€ë³¸ ì‘ì„±"""
    if not gemini_key: return None
    
    try:
        genai_old.configure(api_key=gemini_key)
        # ìˆ˜ì •: ëª¨ë¸ëª…ì„ 2.5(ì¡´ì¬ì•ˆí•¨) -> 1.5-flashë¡œ ë³€ê²½
        model = genai_old.GenerativeModel('gemini-1.5-flash')
        
        prompt = f"""
        Act as a professional YouTube content researcher and writer.
        Topic: '{topic}'
        
        [STRICT LANGUAGE RULES]
        1. "narrative": Must be in **KOREAN (í•œêµ­ì–´)** for the voiceover.
        2. "visual_prompt": Must be in **ENGLISH** (recommended for better image gen) or KOREAN.
        
        [INSTRUCTION - DYNAMIC VISUALS]
        1. **NO STATIC POSES:** Do not describe characters just standing.
        2. **ACTION & MOTION:** Describe specific moments (e.g., "running," "laughing").
        3. **CAMERA ANGLES:** Use "low angle," "close-up," etc.
        
        [CHARACTER CONSISTENCY]
        Start visual prompt with: "{character_desc}"
        
        [STYLE]
        End visual prompt with: "{video_style}"
        
        Output ONLY valid JSON format:
        {{
          "video_title": "Title Here",
          "scenes": [
            {{ 
               "seq": 1, 
               "narrative": "í•œêµ­ì–´ ë‚´ë ˆì´ì…˜", 
               "visual_prompt": "Visual description..." 
            }}
          ]
        }}
        Generate exactly {num_scenes} scenes.
        """
        response = model.generate_content(prompt)
        text = response.text.strip().replace("```json", "").replace("```", "")
        return json.loads(text)
    except Exception as e:
        st.error(f"ğŸ§  Gemini ê¸°íš ì˜¤ë¥˜: {e}")
        return None

def generate_image_google(prompt, filename):
    """[Image] Gemini (New SDK): ì´ë¯¸ì§€ ìƒì„±"""
    if not gemini_key: return None
    
    output_path = os.path.join(tempfile.gettempdir(), filename)

    try:
        client = genai.Client(api_key=gemini_key)
        # ëª¨ë¸ ID í™•ì¸ í•„ìš” (imagen-3.0-generate-001 ë˜ëŠ” gemini-pro-vision ë“± ìƒí™©ì— ë§ê²Œ)
        # í˜„ì¬ ì½”ë“œì˜ gemini-3-pro-image-previewëŠ” Preview ê¶Œí•œì´ ìˆì–´ì•¼ ì‘ë™í•©ë‹ˆë‹¤.
        model_id = "gemini-2.0-flash-exp" # í˜¹ì€ "imagen-3.0-generate-001"
        
        # *ì°¸ê³ : Gemini 2.0 Flash ExpëŠ” ì´ë¯¸ì§€ ìƒì„±ì„ ì§€ì›í•˜ì§€ë§Œ, 
        # ì „ìš© Imagen ëª¨ë¸ì„ ì“´ë‹¤ë©´ ì½”ë“œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
        # ì—¬ê¸°ì„œëŠ” ì‘ì„±í•´ì£¼ì‹  ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
        
        contents = [types.Content(role="user", parts=[types.Part.from_text(text=prompt)])]
        generate_content_config = types.GenerateContentConfig(
            response_modalities=["IMAGE"],
            image_config=types.ImageConfig(image_size="1K"), # í˜¹ì€ "1024x1024" ë“± SDK ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„
        )

        response = client.models.generate_content(
            model=model_id,
            contents=contents,
            config=generate_content_config,
        )
        
        if response.candidates and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if part.inline_data and part.inline_data.data:
                    with open(output_path, "wb") as f:
                        f.write(part.inline_data.data)
                    return output_path
        
        st.warning("âš ï¸ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ëª¨ë¸ ì‘ë‹µ ì—†ìŒ).")
        return None

    except Exception as e:
        st.error(f"ğŸ¨ Google ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def generate_audio(text, filename):
    """[Voice] Google TTS"""
    output_path = os.path.join(tempfile.gettempdir(), filename)
    
    # ì¸ì¦ ì²˜ë¦¬ ë¡œì§ ë‹¨ìˆœí™” ë° ê°•í™”
    credentials = None
    
    try:
        # 1. Secret/Envì— JSON ë‚´ìš©ì´ í†µì§¸ë¡œ ìˆëŠ” ê²½ìš° (Streamlit Cloud ê¶Œì¥)
        if tts_key_json:
            try:
                creds_info = json.loads(tts_key_json, strict=False)
                credentials = service_account.Credentials.from_service_account_info(creds_info)
            except json.JSONDecodeError:
                st.error("TTS JSON í‚¤ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return None
        
        # 2. ë¡œì»¬ íŒŒì¼ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°
        elif tts_key_path and os.path.exists(tts_key_path):
            credentials = service_account.Credentials.from_service_account_file(tts_key_path)
            
        else:
            # í•˜ë“œì½”ë”©ëœ íŒŒì¼ëª…ì€ ì œê±°í•˜ê³  ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
            st.error("âŒ TTS ì¸ì¦ í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (.env ë˜ëŠ” secrets.toml í™•ì¸)")
            return None

        client = texttospeech.TextToSpeechClient(credentials=credentials)
        input_text = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Standard-C", ssml_gender=texttospeech.SsmlVoiceGender.MALE)
        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
        
        response = client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)
        with open(output_path, "wb") as out:
            out.write(response.audio_content)
        return output_path
        
    except Exception as e:
        st.error(f"ğŸ™ï¸ TTS ì˜¤ë¥˜: {e}")
        return None

def create_zoom_effect(clip, zoom_ratio=0.04):
    """Zoom Effect (OpenCV í•„ìš”)"""
    try:
        import cv2
    except ImportError:
        # OpenCV ì—†ìœ¼ë©´ íš¨ê³¼ ì—†ì´ ì›ë³¸ ë¦¬í„´
        return clip

    def effect(get_frame, t):
        img = get_frame(t)
        h, w = img.shape[:2]
        scale = 1 + zoom_ratio * t
        new_w, new_h = int(w * scale), int(h * scale)
        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        x = (new_w - w) // 2
        y = (new_h - h) // 2
        return img_resized[y:y+h, x:x+w]

    return clip.fl(effect)

# --- 3. ë©”ì¸ ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬ ---

topic = st.text_input("ì˜ìƒ ì£¼ì œ (Topic)", placeholder="ì˜ˆ: ë§›ìˆëŠ” ê¹€ì¹˜ì°Œê°œ ë“ì´ëŠ” ë²•")

if st.button("ğŸš€ ì˜ìƒ ìƒì„± ì‹œì‘", type="primary"):
    if not topic:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    status_box = st.status("ğŸ—ï¸ ì‘ì—… ì‹œì‘...", expanded=True)
    
    # Phase 1
    status_box.write("ğŸ§  Phase 1: ì‹œë‚˜ë¦¬ì˜¤ ê¸°íš ì¤‘ (Gemini 1.5 Flash)...")
    script_data = generate_script_json(topic, character_desc)
    
    if not script_data:
        status_box.update(label="âŒ ê¸°íš ì‹¤íŒ¨", state="error")
        st.stop()
        
    scenes = script_data.get("scenes", [])
    st.json(script_data) # ë””ë²„ê¹…ìš© í‘œì‹œ
    
    # Phase 2
    status_box.write("ğŸ¨ Phase 2: ì´ë¯¸ì§€ ë° ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")
    progress_bar = st.progress(0)
    generated_clips = []
    
    for i, scene in enumerate(scenes):
        idx = scene['seq']
        status_box.write(f"  - Scene {idx} ìƒì„± ì¤‘...")
        
        # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ timestamp ì¶”ê°€ ê¶Œì¥
        timestamp = int(time.time())
        img_name = f"img_{idx}_{timestamp}.png"
        aud_name = f"aud_{idx}_{timestamp}.mp3"
        
        aud_path = generate_audio(scene['narrative'], aud_name)
        img_path = generate_image_google(scene['visual_prompt'], img_name)
        
        if img_path and aud_path:
            try:
                audio_clip = AudioFileClip(aud_path)
                # ì´ë¯¸ì§€ ì§€ì†ì‹œê°„ì„ ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¤
                img_clip = ImageClip(img_path).set_duration(audio_clip.duration).resize(height=720)
                video_clip = create_zoom_effect(img_clip) 
                video_clip = video_clip.set_audio(audio_clip)
                generated_clips.append(video_clip)
            except Exception as e:
                st.warning(f"Scene {idx} í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
        
        progress_bar.progress((i + 1) / len(scenes))
        
    # Phase 3
    if generated_clips:
        status_box.write("ğŸ¬ Phase 3: ìµœì¢… ë Œë”ë§ ì¤‘ (FFmpeg)...")
        try:
            final_video = concatenate_videoclips(generated_clips, method="compose")
            
            # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            safe_title = "".join([c for c in topic if c.isalnum()]).strip()
            output_path = os.path.join(tempfile.gettempdir(), f"{safe_title}_final.mp4")
            
            final_video.write_videofile(output_path, fps=24, codec='libx264', audio_codec='aac', preset='ultrafast')
            
            status_box.update(label="âœ… ì™„ë£Œ!", state="complete", expanded=False)
            st.success("ğŸ‰ ì˜ìƒ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.video(output_path)
            
        except Exception as e:
            st.error(f"ë Œë”ë§ ì˜¤ë¥˜: {e}")
    else:
        st.error("âŒ ìƒì„±ëœ í´ë¦½ì´ ì—†ì–´ ì˜ìƒì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
