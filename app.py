import streamlit as st
import os
import json
import tempfile
import time
import requests
import numpy as np
from PIL import Image, ImageDraw, ImageFont # Pillow ëª¨ë“ˆ
import random

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì˜ˆì™¸ ì²˜ë¦¬ ---
# 1. Google GenAI (í…ìŠ¤íŠ¸ìš© - êµ¬ë²„ì „ SDK)
import google.generativeai as genai_old

# 2. Google GenAI (ì´ë¯¸ì§€ìš© - ì‹ ë²„ì „ SDK)
# pip install google-genai
try:
    from google import genai
    from google.genai import types
except ImportError:
    st.error("âŒ 'google-genai' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-genai")
    st.stop()

# 3. Google TTS
from google.cloud import texttospeech
from google.oauth2 import service_account

# 4. Pillow íŒ¨ì¹˜ (MoviePy 1.x í˜¸í™˜ì„±)
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

# 5. MoviePy
from moviepy.editor import *

# 6. .env ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# --- 1. í™˜ê²½ ë° UI ì„¤ì • ---
st.set_page_config(page_title="AI ì˜ìƒ ê³µì¥ (Google Edition)", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ AI ì˜ìƒ ê³µì¥ (Gemini 3 Pro Image)")

# --- [ì•ˆì „ì¥ì¹˜] Secrets ì¡°íšŒ í•¨ìˆ˜ ---
def get_secret(key_name):
    """st.secrets -> os.environ ìˆœì„œë¡œ í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        if key_name in st.secrets:
            return st.secrets[key_name]
    except (FileNotFoundError, AttributeError):
        pass
    return os.getenv(key_name)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì œì–´ê¸°")
    
    gemini_key = get_secret("GOOGLE_API_KEY")
    tts_key_path = get_secret("GOOGLE_APPLICATION_CREDENTIALS") # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    tts_key_json = get_secret("GOOGLE_APPLICATION_CREDENTIALS_JSON") # í´ë¼ìš°ë“œìš© JSON ë‚´ìš©
    
    # ìƒíƒœ í‘œì‹œ
    if gemini_key:
        st.success("âœ… Gemini API: Connected")
    else:
        st.error("âŒ Gemini API: Missing Key")
        
    if tts_key_path or tts_key_json:
        st.success("âœ… Google TTS: Connected")
    else:
        st.error("âŒ Google TTS: Missing Credentials")
    
    st.divider()
    
    st.subheader("ğŸ–¼ï¸ ìºë¦­í„° ì„¤ì •")
    default_char = "A young Korean office worker in a suit, simple clean lines, distinct facial features"
    character_desc = st.text_area("ì£¼ì¸ê³µ ì™¸ëª¨ ë¬˜ì‚¬", value=default_char, height=80)
    video_style = st.selectbox("í™”í’ (Style)", ["2D Webtoon Style", "Anime Style", "Realistic Cinematic", "Oil Painting"], index=0)
    
    num_scenes = st.slider("ìƒì„±í•  ì”¬(Scene) ê°œìˆ˜ (ê¶Œì¥: 4ê°œ ì´ìƒ)", 2, 6, 4)

    st.divider()
    st.subheader("ğŸµ ë°°ê²½ìŒì•… (BGM)")
    bgm_mood = st.selectbox(
        "ë¶„ìœ„ê¸° ì„ íƒ", 
        ["ğŸŒ ë°ê³  ê²½ì¾Œí•œ (Bright)", "â˜• ì°¨ë¶„í•œ (Calm)", "ğŸ”¥ ë°•ì§„ê° ë„˜ì¹˜ëŠ” (Epic)", "ğŸ”‡ ì—†ìŒ (Mute)"],
        index=0
    )

# --- 2. í•µì‹¬ ëª¨ë“ˆ í•¨ìˆ˜ ---
def generate_script_json(topic, character_desc, num_scenes):
    """
    [Text] Gemini: í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ ê·œì¹™ ì¶”ê°€
    """
    if not gemini_key: return None
    
    try:
        genai_old.configure(api_key=gemini_key)
        model = genai_old.GenerativeModel('gemini-2.5-flash') 
        
        prompt = f"""
        You are a YouTube Shorts Director. Create a script for: '{topic}'
        
        [CONSTRAINT - SCENE COUNT]
        You must generate **EXACTLY {num_scenes} scenes**.
        
        [LANGUAGE RULES]
        1. "narrative": **KOREAN (í•œêµ­ì–´)**. Casual spoken style.
        2. "visual_prompt": **ENGLISH (ì˜ì–´)** for descriptions.
        3. **[CRITICAL] KOREAN TEXT IN IMAGE**: 
           - If a scene needs specific text (e.g., a signboard, a letter, a phone screen), describe the object in English but write the **text content in KOREAN inside double quotes**.
           - Format: `Object description ..., text reads "í•œêµ­ì–´ ë‚´ìš©", style ...`
           - Example: `A neon sign on a dark street that says "ë¼ë©´ ë§›ì§‘" || A hand holding a smartphone showing a message "ì…ê¸ˆ ì™„ë£Œ"`
        
        [CONTENT GUIDE]
        - Split visual actions using " || " for dynamic cuts.
        - **DO NOT** include the character description in the JSON output.
        
        [AUDIO GUIDE]
        - **Sound Effect**: Choose ONE suitable sound effect for each scene from this list:
          ["Whoosh (ì „í™˜)", "Ding (ì •ë‹µ/ì•„ì´ë””ì–´)", "Camera (ì°°ì¹µ)", "Pop (ë“±ì¥)", "Keyboard (íƒ€ì)", "None"]
          - Use "Whoosh (ì „í™˜)" for fast action.
          - Use "Ding (ì •ë‹µ/ì•„ì´ë””ì–´)" for key information.
          - Use "Camera (ì°°ì¹µ)" for visual focus.
          
        [OUTPUT JSON FORMAT]
        {{
          "video_title": "Korean Title",
          "scenes": [
            {{ 
                "seq": 1, 
                "narrative": "ì´ ê°„íŒ ë³´ì´ì‹œì£ ?", 
                "visual_prompt": "A bright yellow wooden sign that reads \"ì›ì¡° ë§›ì§‘\" hanging on a wall",
                "sound_effect": "Ding (ì •ë‹µ/ì•„ì´ë””ì–´)" 
            }},
            ...
          ]
        }}
        """
        
        response = model.generate_content(prompt)
        text = response.text.strip()
        if text.startswith("```json"): text = text[7:]
        if text.endswith("```"): text = text[:-3]
        return json.loads(text)
        
    except Exception as e:
        st.error(f"ê¸°íš ì˜¤ë¥˜: {e}")
        return None

def generate_image_google(prompt, filename):
    """[Image] Gemini (New SDK): ì´ë¯¸ì§€ ìƒì„±"""
    if not gemini_key: return None
    
    output_path = os.path.join(tempfile.gettempdir(), filename)

    try:
        client = genai.Client(api_key=gemini_key)
        # ëª¨ë¸ ID í™•ì¸ í•„ìš” (imagen-3.0-generate-001 ë˜ëŠ” gemini-pro-vision ë“± ìƒí™©ì— ë§ê²Œ)
        # í˜„ì¬ ì½”ë“œì˜ gemini-3-pro-image-previewëŠ” Preview ê¶Œí•œì´ ìˆì–´ì•¼ ì‘ë™í•©ë‹ˆë‹¤.
        model_id = "gemini-3-pro-image-preview" # í˜¹ì€ "imagen-3.0-generate-001"
        
        # *ì°¸ê³ : Gemini 2.0 Flash ExpëŠ” ì´ë¯¸ì§€ ìƒì„±ì„ ì§€ì›í•˜ì§€ë§Œ, 
        # ì „ìš© Imagen ëª¨ë¸ì„ ì“´ë‹¤ë©´ ì½”ë“œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
        # ì—¬ê¸°ì„œëŠ” ì‘ì„±í•´ì£¼ì‹  ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
        
        contents = [types.Content(role="user", parts=[types.Part.from_text(text=prompt)])]
        generate_content_config = types.GenerateContentConfig(
            response_modalities=["IMAGE"],
            image_config=types.ImageConfig(image_size="1K"), # í˜¹ì€ "1024x1024" ë“± SDK ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„
        )

        response = client.models.generate_content(
            model=model_id,
            contents=contents,
            config=generate_content_config,
        )
        
        if response.candidates and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if part.inline_data and part.inline_data.data:
                    with open(output_path, "wb") as f:
                        f.write(part.inline_data.data)
                    return output_path
        
        st.warning("âš ï¸ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ëª¨ë¸ ì‘ë‹µ ì—†ìŒ).")
        return None

    except Exception as e:
        st.error(f"ğŸ¨ Google ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def generate_audio(text, filename):
    """[Voice] Google TTS"""
    output_path = os.path.join(tempfile.gettempdir(), filename)
    
    # ì¸ì¦ ì²˜ë¦¬ ë¡œì§ ë‹¨ìˆœí™” ë° ê°•í™”
    credentials = None
    
    try:
        # 1. Secret/Envì— JSON ë‚´ìš©ì´ í†µì§¸ë¡œ ìˆëŠ” ê²½ìš° (Streamlit Cloud ê¶Œì¥)
        if tts_key_json:
            try:
                creds_info = json.loads(tts_key_json, strict=False)
                credentials = service_account.Credentials.from_service_account_info(creds_info)
            except json.JSONDecodeError:
                st.error("TTS JSON í‚¤ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return None
        
        # 2. ë¡œì»¬ íŒŒì¼ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°
        elif tts_key_path and os.path.exists(tts_key_path):
            credentials = service_account.Credentials.from_service_account_file(tts_key_path)
            
        else:
            # í•˜ë“œì½”ë”©ëœ íŒŒì¼ëª…ì€ ì œê±°í•˜ê³  ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
            st.error("âŒ TTS ì¸ì¦ í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (.env ë˜ëŠ” secrets.toml í™•ì¸)")
            return None

        client = texttospeech.TextToSpeechClient(credentials=credentials)
        input_text = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Standard-C", ssml_gender=texttospeech.SsmlVoiceGender.MALE)
        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
        
        response = client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)
        with open(output_path, "wb") as out:
            out.write(response.audio_content)
        return output_path
        
    except Exception as e:
        st.error(f"ğŸ™ï¸ TTS ì˜¤ë¥˜: {e}")
        return None

def apply_random_motion(clip):
    """
    [Motion] ì¤Œì¸, ì¤Œì•„ì›ƒ, ì¢Œìš°/ìƒí•˜ íŒ¨ë‹ ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.
    """
    try:
        import cv2
    except ImportError:
        return clip

    # ê°€ëŠ¥í•œ íš¨ê³¼ ëª©ë¡
    effects = ['zoom_in', 'zoom_out', 'pan_left', 'pan_right', 'pan_up', 'pan_down']
    effect_type = random.choice(effects)
    
    # íš¨ê³¼ ê°•ë„ (ë„ˆë¬´ ì–´ì§€ëŸ½ì§€ ì•Šê²Œ ì¡°ì ˆ)
    speed = 0.04  # ì›€ì§ì„ ì†ë„

    def fl(get_frame, t):
        img = get_frame(t)
        h, w = img.shape[:2]
        
        # ì‹œê°„ tì— ë”°ë¥¸ ì§„í–‰ë¥  (0.0 ~ 1.0) -> í´ë¦½ ëë‚  ë•Œ ìµœëŒ€ ì›€ì§ì„
        progress = t / clip.duration if clip.duration > 0 else 0
        scale = 1 + (speed * progress) # 1.0 ~ 1.04
        
        # ì›ë³¸ í¬ê¸° ìœ ì§€ë¥¼ ìœ„í•œ ë¦¬ì‚¬ì´ì§• ê³„ì‚°
        new_w, new_h = int(w * scale), int(h * scale)
        
        # OpenCVë¡œ ì´ë¯¸ì§€ í™•ëŒ€ (ê¸°ë³¸ ë² ì´ìŠ¤)
        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # ì˜ë¼ë‚¼ ìœ„ì¹˜(Crop) ê²°ì • ë¡œì§
        if effect_type == 'zoom_in':
            # ì¤‘ì•™ì„ í–¥í•´ ì¤Œì¸ (ì ì  ì•ˆìª½ì„ ë³´ì—¬ì¤Œ)
            x = (new_w - w) // 2
            y = (new_h - h) // 2
            
        elif effect_type == 'zoom_out':
            # ì¤Œì•„ì›ƒì€ ë°˜ëŒ€ë¡œ êµ¬í˜„ì´ ê¹Œë‹¤ë¡œìš°ë¯€ë¡œ, 
            # "ì´ë¯¸ í™•ëŒ€ëœ ìƒíƒœì—ì„œ ì‹œì‘í•´ì„œ ì›ë˜ëŒ€ë¡œ ëŒì•„ì˜¤ëŠ”" ë¡œì§ ëŒ€ì‹ 
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ "ì•½í•œ ì¤Œì¸"ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì—­ë°©í–¥ êµ¬í˜„ í•„ìš”.
            # (ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•˜ê¸° ìœ„í•´ zoom_inê³¼ ì¤Œ í¬ì¸íŠ¸ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •)
            x = (new_w - w) // 2
            y = (new_h - h) // 2
            
        elif effect_type == 'pan_left':
            # ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ ì´ë™ (ë³´ì—¬ì£¼ëŠ” ë·°í¬íŠ¸ê°€ ì™¼ìª½ìœ¼ë¡œ ê° -> xëŠ” 0ì—ì„œ ì‹œì‘í•´ì„œ ì»¤ì§?? ë°˜ëŒ€ì„)
            # ì´ë¯¸ì§€ì˜ ì˜¤ë¥¸ìª½ ëì„ ë³´ì—¬ì£¼ë‹¤ê°€ -> ì™¼ìª½ìœ¼ë¡œ ì´ë™
            # x: (new_w - w) -> 0 (ê°ì†Œ)
            max_x = new_w - w
            x = int(max_x * (1 - progress))
            y = (new_h - h) // 2 # YëŠ” ì¤‘ì•™ ê³ ì •
            
        elif effect_type == 'pan_right':
            # ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™
            # x: 0 -> (new_w - w) (ì¦ê°€)
            max_x = new_w - w
            x = int(max_x * progress)
            y = (new_h - h) // 2
            
        elif effect_type == 'pan_up':
            # ì•„ë˜ì—ì„œ ìœ„ë¡œ
            x = (new_w - w) // 2
            max_y = new_h - h
            y = int(max_y * (1 - progress))
            
        elif effect_type == 'pan_down':
            # ìœ„ì—ì„œ ì•„ë˜ë¡œ
            x = (new_w - w) // 2
            max_y = new_h - h
            y = int(max_y * progress)
            
        else:
            # ê¸°ë³¸ ì¤‘ì•™
            x, y = (new_w - w) // 2, (new_h - h) // 2

        # ì¢Œí‘œê°€ ìŒìˆ˜ê±°ë‚˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ í´ë¦¬í•‘
        x = max(0, min(x, new_w - w))
        y = max(0, min(y, new_h - h))
        
        return img_resized[y:y+h, x:x+w]

    return clip.fl(fl)

def get_bgm_path(mood):
    """
    ì„ íƒëœ ë¶„ìœ„ê¸°(mood)ì— ë§ëŠ” ë¬´ë£Œ BGMì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    (ì €ì‘ê¶Œ ë¬´ë£Œ ìŒì›: Kevin MacLeod ë“± Open Source í™œìš©)
    """
    if mood == "ğŸ”‡ ì—†ìŒ (Mute)":
        return None
        
    # ë¶„ìœ„ê¸°ë³„ ìŒì› URL (ì•ˆì •ì ì¸ GitHub Raw ì†ŒìŠ¤ ë“±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìœ¼ë‚˜, ì˜ˆì‹œë¡œ ë¬´ë£Œ ìŒì› ë§í¬ ì‚¬ìš©)
    # ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ë³¸ì¸ì˜ ì„œë²„ë‚˜ S3 ë§í¬ë¡œ êµì²´í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    bgm_urls = {
        "ğŸŒ ë°ê³  ê²½ì¾Œí•œ (Bright)": "https://www.bensound.com/bensound-music/bensound-ukulele.mp3", # ì˜ˆì‹œ URL
        "â˜• ì°¨ë¶„í•œ (Calm)": "https://www.bensound.com/bensound-music/bensound-slowmotion.mp3", 
        "ğŸ”¥ ë°•ì§„ê° ë„˜ì¹˜ëŠ” (Epic)": "https://www.bensound.com/bensound-music/bensound-evolution.mp3"
    }
    
    url = bgm_urls.get(mood)
    if not url: return None
    
    # ì„ì‹œ íŒŒì¼ëª… (ë¶„ìœ„ê¸°ë³„ë¡œ ìºì‹±)
    filename = f"bgm_{mood[:2]}.mp3"
    filepath = os.path.join(tempfile.gettempdir(), filename)
    
    # ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ë°›ì€ íŒŒì¼ì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš© (ì†ë„ í–¥ìƒ)
    if os.path.exists(filepath):
        return filepath
        
    try:
        # User-Agent í—¤ë” ì¶”ê°€ (ì°¨ë‹¨ ë°©ì§€)
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        with open(filepath, "wb") as f:
            f.write(response.content)
        return filepath
    except Exception as e:
        st.warning(f"BGM ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def get_sfx_path(sfx_name):
    """
    íš¨ê³¼ìŒ ì´ë¦„ì„ ë°›ì•„ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    (ìì£¼ ì“°ëŠ” 5ê°€ì§€ í•„ìˆ˜ íš¨ê³¼ìŒ ë§¤í•‘)
    """
    if not sfx_name or sfx_name == "None":
        return None
        
    # íš¨ê³¼ìŒ ë§¤í•‘ (ë¬´ë£Œ ìŒì› URL ì˜ˆì‹œ)
    sfx_library = {
        "Whoosh (ì „í™˜)": "https://www.soundjay.com/transition/sounds/swoosh-01.mp3",
        "Ding (ì •ë‹µ/ì•„ì´ë””ì–´)": "https://www.soundjay.com/misc/sounds/bell-ringing-05.mp3",
        "Camera (ì°°ì¹µ)": "https://www.soundjay.com/mechanical/sounds/camera-shutter-click-01.mp3",
        "Pop (ë“±ì¥)": "https://www.soundjay.com/button/sounds/button-16.mp3",
        "Keyboard (íƒ€ì)": "https://www.soundjay.com/mechanical/sounds/typewriter-6.mp3"
    }
    
    url = sfx_library.get(sfx_name)
    if not url: return None
    
    # íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜
    safe_name = "".join(x for x in sfx_name if x.isalnum())
    filename = f"sfx_{safe_name}.mp3"
    filepath = os.path.join(tempfile.gettempdir(), filename)
    
    # ìºì‹± (ì´ë¯¸ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨)
    if os.path.exists(filepath):
        return filepath
        
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        with open(filepath, "wb") as f:
            f.write(response.content)
        return filepath
    except Exception as e:
        return None

def get_korean_font():
    """
    í•œê¸€ í°íŠ¸(ë‚˜ëˆ”ê³ ë”•)ë¥¼ ì„ì‹œ í´ë”ì— ë‹¤ìš´ë¡œë“œí•˜ì—¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    (í•œê¸€ ê¹¨ì§ ë°©ì§€ìš©)
    """
    font_url = "https://github.com/google/fonts/raw/main/ofl/nanumgothic/NanumGothic-Bold.ttf"
    font_path = os.path.join(tempfile.gettempdir(), "NanumGothic-Bold.ttf")
    
    if not os.path.exists(font_path):
        try:
            response = requests.get(font_url)
            with open(font_path, "wb") as f:
                f.write(response.content)
        except Exception:
            return None # ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‹œë„
            
    return font_path

def create_subtitle(text, duration, font_path):
    """
    [ë¬´ì„¤ì¹˜ ë²„ì „] Pillowë¥¼ ì‚¬ìš©í•˜ì—¬ ìë§‰ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ImageMagickì´ í•„ìš” ì—†ì–´ ì˜¤ë¥˜ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        # 1. ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì • (HD í•´ìƒë„ ê¸°ì¤€)
        w, h = 1280, 720
        # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± (RGBA)
        img = Image.new('RGBA', (w, h), (255, 255, 255, 0))
        draw = ImageDraw.Draw(img)
        
        # 2. í°íŠ¸ ë¡œë“œ
        font_size = 50
        try:
            if font_path:
                font = ImageFont.truetype(font_path, font_size)
            else:
                # í°íŠ¸ ê²½ë¡œ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ (í•œê¸€ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ)
                font = ImageFont.load_default()
        except Exception:
            font = ImageFont.load_default()

        # 3. í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (ê°„ë‹¨ ë²„ì „)
        if len(text) > 25:
            text = text[:25] + "\n" + text[25:]
        
        # 4. í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚° ë° ìœ„ì¹˜ ì¡ê¸° (ì¤‘ì•™ í•˜ë‹¨)
        # textbboxëŠ” Pillow ìµœì‹  ë²„ì „ ê¸°ì¤€
        left, top, right, bottom = draw.textbbox((0, 0), text, font=font)
        text_w = right - left
        text_h = bottom - top
        
        x = (w - text_w) / 2
        y = h - 100 # ë°‘ì—ì„œ 100px ìœ„
        
        # 5. ê¸€ì í…Œë‘ë¦¬(Stroke) ê·¸ë¦¬ê¸° (ê²€ì€ìƒ‰)
        stroke_width = 3
        draw.text((x, y), text, font=font, fill="white", stroke_width=stroke_width, stroke_fill="black")

        # 6. MoviePy í´ë¦½ìœ¼ë¡œ ë³€í™˜
        # Pillow ì´ë¯¸ì§€ -> Numpy ë°°ì—´ -> ImageClip
        return ImageClip(np.array(img)).set_duration(duration)

    except Exception as e:
        st.error(f"ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# --- 3. ë©”ì¸ ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ìƒˆë¡œê³ ì¹¨ í•´ë„ ë°ì´í„° ìœ ì§€)
if "script_data" not in st.session_state:
    st.session_state["script_data"] = None
if "step" not in st.session_state:
    st.session_state["step"] = 1

st.divider()
st.header("Step 1. ê¸°íšì•ˆ ì‘ì„±")
topic = st.text_input("ì˜ìƒ ì£¼ì œ (Topic)", placeholder="ì˜ˆ: ì§‘ì—ì„œ ë§Œë“œëŠ” ìŠ¤íƒ€ë²…ìŠ¤ ëŒì²´ë¼ë–¼ ë ˆì‹œí”¼")

# [ë²„íŠ¼ 1] ê¸°íšì•ˆ ìƒì„±
if st.button("ğŸ’¡ 1. ê¸°íšì•ˆ(ëŒ€ë³¸) ìƒì„±í•˜ê¸°", type="primary", use_container_width=True):
    if not topic:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
        
    with st.spinner("ğŸ§  Geminiê°€ ê¸°ìŠ¹ì „ê²°(Hook-Body-CTA) êµ¬ì¡°ë¡œ ê¸°íš ì¤‘ì…ë‹ˆë‹¤..."):
        # 1ë‹¨ê³„ì—ì„œ ë§Œë“  êµ¬ì¡°í™”ëœ í•¨ìˆ˜ í˜¸ì¶œ
        script_data = generate_script_json(topic, character_desc, num_scenes)
        
        if script_data:
            st.session_state["script_data"] = script_data
            st.session_state["step"] = 2
            st.rerun() # í™”ë©´ ê°±ì‹ 
        else:
            st.error("ê¸°íšì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# [UI] ëŒ€ë³¸ ìˆ˜ì • ë° í™•ì • ë‹¨ê³„
if st.session_state["step"] >= 2 and st.session_state["script_data"]:
    st.divider()
    st.header("Step 2. ëŒ€ë³¸ ë° ì—°ì¶œ ìˆ˜ì •")
    st.info("ğŸ’¡ ê¿€íŒ: 'ê·¸ë¦¼ ë¬˜ì‚¬' ì¹¸ì— ` || ` ê¸°í˜¸ë¥¼ ë„£ìœ¼ë©´ ì»·ì´ ìª¼ê°œì§‘ë‹ˆë‹¤. (ì˜ˆ: ë‚¨ìì˜ ì–¼êµ´ || ë†€ë¼ëŠ” í‘œì •)")

    data = st.session_state["script_data"]
    scenes = data.get("scenes", [])
    
    # í¼(Form)ì„ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ë°ì´í„° ìˆ˜ì§‘
    with st.form("script_edit_form"):
        # íƒ€ì´í‹€ ìˆ˜ì •
        new_title = st.text_input("ì˜ìƒ ì œëª©", value=data.get("video_title", ""))
        
        edited_scenes = []
        for i, scene in enumerate(scenes):
            st.subheader(f"ğŸ¬ Scene {scene['seq']} ({scene.get('section', 'General')})")
            
            # ë ˆì´ì•„ì›ƒ 2ë‹¨ ë¶„ë¦¬ (ì™¼ìª½: ëŒ€ë³¸ / ì˜¤ë¥¸ìª½: ê·¸ë¦¼ ë¬˜ì‚¬)
            col1, col2 = st.columns(2)
            
            with col1:
                # keyë¥¼ ê³ ìœ í•˜ê²Œ ì§€ì •í•´ì•¼ í•¨
                new_narrative = st.text_area(
                    label="ğŸ—£ï¸ ë‚´ë ˆì´ì…˜ (í•œêµ­ì–´)", 
                    value=scene['narrative'], 
                    height=100,
                    key=f"narr_area_{i}"
                )
                # íš¨ê³¼ìŒ ì„ íƒ ë©”ë‰´ ì¶”ê°€
                sfx_options = ["None", "Whoosh (ì „í™˜)", "Ding (ì •ë‹µ/ì•„ì´ë””ì–´)", "Camera (ì°°ì¹µ)", "Pop (ë“±ì¥)", "Keyboard (íƒ€ì)"]
                
                # ê¸°íšì•ˆì— ìˆëŠ” ê°’ ì°¾ê¸° (ì—†ìœ¼ë©´ None)
                current_sfx = scene.get('sound_effect', 'None')
                if current_sfx not in sfx_options: current_sfx = "None"
                
                st.selectbox(
                    "ğŸ”Š íš¨ê³¼ìŒ ì„ íƒ", 
                    sfx_options, 
                    index=sfx_options.index(current_sfx),
                    key=f"sfx_select_{i}"
                )
            
            with col2:
                new_visual = st.text_area(
                    label="ğŸ–¼ï¸ ê·¸ë¦¼ ë¬˜ì‚¬ (ì˜ì–´ ê¶Œì¥)", 
                    value=scene['visual_prompt'], 
                    height=100,
                    key=f"vis_area_{i}"
                )
            
            # ìˆ˜ì •ëœ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì„ ì¤€ë¹„ (ì‹¤ì œ ì—…ë°ì´íŠ¸ëŠ” ë²„íŠ¼ í´ë¦­ ì‹œ ì²˜ë¦¬)
            # ì—¬ê¸°ì„œëŠ” í¼ ë‚´ë¶€ë¼ UIë§Œ ë³´ì—¬ì£¼ê³ , ë°ì´í„° ì²˜ë¦¬ëŠ” ì•„ë˜ submit ë²„íŠ¼ ì´í›„ì— í•¨.
            
        # [ë²„íŠ¼ 2] ì˜ìƒ ìƒì„± ì‹œì‘
        generate_btn = st.form_submit_button("ğŸ¬ 2. ì´ ë‚´ìš©ìœ¼ë¡œ ì˜ìƒ ë§Œë“¤ê¸° (Start Generation)", type="primary", use_container_width=True)

    # í¼ ì œì¶œ ë²„íŠ¼ì´ ëˆŒë ¸ì„ ë•Œ ì‹¤í–‰
    if generate_btn:
        # ìˆ˜ì •ëœ ë°ì´í„° ìˆ˜ì§‘
        final_scenes = []
        for i, org_scene in enumerate(scenes):
            final_scenes.append({
                "seq": org_scene['seq'],
                "narrative": st.session_state[f"narr_area_{i}"],
                "visual_prompt": st.session_state[f"vis_area_{i}"],
                "sound_effect": st.session_state[f"sfx_select_{i}"] # <--- ì¶”ê°€
            })
            
        # ë³¸ê²©ì ì¸ ìƒì„± ì‹œì‘
        status_box = st.status("ğŸ—ï¸ ì˜ìƒ ì œì‘ ê³µì¥ ê°€ë™ ì¤‘...", expanded=True)
        
        # --- Phase 2: ë‹¤ì´ë‚˜ë¯¹ ì»· ìƒì„± (ì»· ìª¼ê°œê¸° ì ìš©) ---
        status_box.write("ğŸ¨ Phase 2: ë‹¤ì´ë‚˜ë¯¹ ì»·(ì´ë¯¸ì§€ ë¶„í• ) ë° ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")
        progress_bar = st.progress(0)
        generated_clips = []
        
        for i, scene in enumerate(final_scenes):
            idx = scene['seq']
            status_box.write(f"  - Scene {idx} ì‘ì—… ì¤‘...")
            
            timestamp = int(time.time())
            
            # [ìˆ˜ì •] ë³€ìˆ˜ ì •ì˜ê°€ ë¨¼ì € ìˆì–´ì•¼ í•©ë‹ˆë‹¤!
            aud_name = f"aud_{idx}_{timestamp}.mp3"

            # 1. ì˜¤ë””ì˜¤ ë¨¼ì € ìƒì„± (ê¸¸ì´ë¥¼ ì•Œì•„ì•¼ ì»·ì„ ë‚˜ëˆŒ ìˆ˜ ìˆìŒ)
            aud_path = generate_audio(scene['narrative'], aud_name)
            
            if not aud_path: continue
            
            audio_clip = AudioFileClip(aud_path)
            
            # --- [NEW] íš¨ê³¼ìŒ ë¯¹ì‹± ë¡œì§ ì‹œì‘ ---
            sfx_name = scene.get('sound_effect')
            sfx_path = get_sfx_path(sfx_name)
            
            if sfx_path:
                try:
                    sfx_clip = AudioFileClip(sfx_path)
                    sfx_clip = sfx_clip.volumex(0.6)
                    audio_clip = CompositeAudioClip([audio_clip, sfx_clip])
                    
                except Exception as e:
                    st.warning(f"íš¨ê³¼ìŒ í•©ì„± ì‹¤íŒ¨: {e}")
            # --- [NEW] íš¨ê³¼ìŒ ë¯¹ì‹± ë¡œì§ ë ---
            
            scene_duration = audio_clip.duration
            
            # 2. ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ë¶„ì„ ('||' ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œê¸°)
            raw_prompts = scene['visual_prompt'].split('||')            
            scene_sub_clips = [] 
            
            # ì»· ë‹¹ ì§€ì† ì‹œê°„ ê³„ì‚°
            # í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜ ì¶”ê°€
            valid_prompts = [p.strip() for p in raw_prompts if p.strip()]
            if not valid_prompts: valid_prompts = [scene['visual_prompt']]
            
            clip_duration = scene_duration / len(valid_prompts)
            
            # 3. ê° ì»· ë³„ë¡œ ì´ë¯¸ì§€ ìƒì„± ë° í´ë¦½ ë§Œë“¤ê¸°            
            for sub_idx, raw_text in enumerate(valid_prompts):
                
                # [ìºë¦­í„°/í™”í’ ê°•ì œ ì£¼ì…]
                final_prompt = f"{character_desc}, {raw_text}, {video_style}, cinematic lighting"
                
                img_name = f"img_{idx}_{sub_idx}_{timestamp}.png"
                status_box.write(f"    â”” ì»· {sub_idx+1}: {raw_text[:15]}...")
                
                img_path = generate_image_google(final_prompt, img_name)
                
                if img_path:
                    try:
                        # ì´ë¯¸ì§€ í´ë¦½ ìƒì„±
                        sub_clip = ImageClip(img_path).set_duration(clip_duration).resize(height=720)
                        
                        # [ëœë¤ ëª¨ì…˜ ì ìš©]
                        sub_clip = apply_random_motion(sub_clip)
                        
                        scene_sub_clips.append(sub_clip)
                    except Exception as e:
                        st.warning(f"ì´ë¯¸ì§€ í´ë¦½ ì˜¤ë¥˜: {e}")
            
            # 4. ì¡°ê° ì˜ìƒë“¤ í•©ì¹˜ê¸° + ì˜¤ë””ì˜¤ ì…íˆê¸°
            if scene_sub_clips:
                try:
                    full_scene_clip = concatenate_videoclips(scene_sub_clips, method="compose")
                    full_scene_clip = full_scene_clip.set_audio(audio_clip)
                    generated_clips.append(full_scene_clip)
                except Exception as e:
                    st.error(f"Scene {idx} í•©ì¹˜ê¸° ì‹¤íŒ¨: {e}")
            
            progress_bar.progress((i + 1) / len(final_scenes))

        # Phase 3: Final Rendering (BGM Mixing ì¶”ê°€)
        if generated_clips:
            status_box.write("ğŸ¬ Phase 3: ì˜ìƒ í•©ì¹˜ê¸° ë° BGM ë¯¹ì‹± ì¤‘...")
            try:
                # 1. ì»· í¸ì§‘ëœ ì˜ìƒ ì—°ê²°
                final_video = concatenate_videoclips(generated_clips, method="compose")
                
                # 2. BGM ì²˜ë¦¬ ë¡œì§
                bgm_path = get_bgm_path(bgm_mood)
                
                if bgm_path:
                    try:
                        # BGM ë¡œë“œ
                        bgm_clip = AudioFileClip(bgm_path)
                        
                        # ì˜ìƒ ê¸¸ì´ì— ë§ì¶° BGM ë°˜ë³µ(Loop) ë˜ëŠ” ìë¥´ê¸°
                        # (ì˜ìƒë³´ë‹¤ BGMì´ ì§§ìœ¼ë©´ ë°˜ë³µ, ê¸¸ë©´ ìë¦„)
                        if bgm_clip.duration < final_video.duration:
                            # ì§ìˆ˜ ë²ˆ ë°˜ë³µí•´ì„œ ì¶©ë¶„íˆ ê¸¸ê²Œ ë§Œë“¦
                            loop_count = int(final_video.duration // bgm_clip.duration) + 2
                            bgm_clip = concatenate_audioclips([bgm_clip] * loop_count)
                        
                        bgm_clip = bgm_clip.set_duration(final_video.duration)
                        
                        # ë³¼ë¥¨ ì¡°ì ˆ (ê°€ì¥ ì¤‘ìš”!)
                        # ëª©ì†Œë¦¬(Voice)ëŠ” 100%, BGMì€ 10%~15% ìˆ˜ì¤€ìœ¼ë¡œ ë‚®ì¶¤
                        voice_clip = final_video.audio.volumex(1.0) # ì›ë³¸ ëª©ì†Œë¦¬ ìœ ì§€
                        bgm_clip = bgm_clip.volumex(0.15)           # ë°°ê²½ìŒì•… 15% (ì€ì€í•˜ê²Œ)
                        
                        # í˜ì´ë“œ ì•„ì›ƒ (ëë‚  ë•Œ 2ì´ˆê°„ ì„œì„œíˆ ì‘ì•„ì§)
                        bgm_clip = bgm_clip.audio_fadeout(2)
                        
                        # ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° (ëª©ì†Œë¦¬ + BGM)
                        final_audio = CompositeAudioClip([voice_clip, bgm_clip])
                        final_video = final_video.set_audio(final_audio)
                        
                    except Exception as e:
                        st.warning(f"BGM í•©ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ(ì˜ìƒì€ BGM ì—†ì´ ìƒì„±ë©ë‹ˆë‹¤): {e}")

                # 3. ìµœì¢… ë‚´ë³´ë‚´ê¸°
                safe_title = "".join([c for c in new_title if c.isalnum()]).strip() or "output"
                output_path = os.path.join(tempfile.gettempdir(), f"{safe_title}_final.mp4")
                
                final_video.write_videofile(output_path, fps=24, codec='libx264', audio_codec='aac', preset='ultrafast')
                
                status_box.update(label="âœ… ì˜ìƒ ì™„ì„±!", state="complete", expanded=False)
                st.balloons()
                st.success(f"ğŸ‰ '{new_title}' ì˜ìƒì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! (BGM: {bgm_mood})")
                st.video(output_path)
                
            except Exception as e:
                st.error(f"ë Œë”ë§ ì˜¤ë¥˜: {e}")