import streamlit as st
import os
import json
import tempfile
import time
import requests
import numpy as np
from PIL import Image, ImageDraw, ImageFont # Pillow ëª¨ë“ˆ
import random
import textwrap

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì˜ˆì™¸ ì²˜ë¦¬ ---
# 1. Google GenAI (í…ìŠ¤íŠ¸ìš© - êµ¬ë²„ì „ SDK)
import google.generativeai as genai_old

# 2. Google GenAI (ì´ë¯¸ì§€ìš© - ì‹ ë²„ì „ SDK)
# pip install google-genai
try:
    from google import genai
    from google.genai import types
except ImportError:
    st.error("âŒ 'google-genai' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-genai")
    st.stop()

# 3. Google TTS
from google.cloud import texttospeech
from google.oauth2 import service_account

# 4. Pillow íŒ¨ì¹˜ (MoviePy 1.x í˜¸í™˜ì„±)
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

# 5. MoviePy
from moviepy.editor import *

# 6. .env ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# --- [ë°ì´í„° ì‚¬ì „] í™”í’ ë° BGM ë§¤í•‘ ---

# 1. í™”í’ (Style) ë§¤í•‘: ì‚¬ìš©ìê°€ ì„ íƒí•˜ë©´ -> ì „ë¬¸ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
STYLE_PROMPTS = {
    "ğŸ“¸ ì‹¤ì‚¬: ì‹œë„¤ë§ˆí‹± (Cinematic)": "Cinematic shot, 4k, hyper-realistic, shallow depth of field, dramatic lighting, shot on Sony A7R",
    "ğŸ“¸ ì‹¤ì‚¬: ì¸ìŠ¤íƒ€ ê°ì„± (Aesthetic)": "Polaroid style, film grain, soft natural lighting, candid shot, aesthetic, VSCO filter",
    "ğŸ¨ 2D: ì›¹íˆ°/ë§Œí™” (Webtoon)": "Korean webtoon style, cel shaded, vibrant colors, clean lines, anime style, manhwa",
    "ğŸ¨ 3D: í”½ì‚¬ ìŠ¤íƒ€ì¼ (3D Animation)": "Disney Pixar style 3D render, cute, soft texture, volumetric lighting, Unreal Engine 5",
    "ğŸ–Œï¸ ì˜ˆìˆ : ìˆ˜ì±„í™” (Watercolor)": "Watercolor painting, soft brush strokes, pastel colors, artistic, dreamy",
    "ğŸŒƒ ì‚¬ì´ë²„í‘í¬ (Cyberpunk)": "Cyberpunk, neon lights, futuristic, dark atmosphere, glowing effects"
}

# --- [ë°ì´í„° ì‚¬ì „ ì¶”ê°€] ì¥ë¥´ë³„ ìµœì í™” ì„¤ì • ---
GENRE_SETTINGS = {
    "ğŸ“° ì •ë³´/ë‰´ìŠ¤ (Info)": {
        "persona": "Professional Journalist",
        "max_chars": 250, # 58ì´ˆ ê½‰ ì±„ì›€
        "structure": "Hook (Shocking Fact) -> Body (3 Key Facts) -> Outro (Conclusion)",
        "tone": "Objective, clear, analytical, trustworthy",
        "pacing": "Fast and informative"
    },
    "ğŸ‘„ ì°/ìŠ¤í† ë¦¬ (Story)": {
        "persona": "Friendly Storyteller",
        "max_chars": 210, # ì—°ê¸°í•  ì‹œê°„ í™•ë³´
        "structure": "Hook (Emotional Reaction) -> Body (Situation & Crisis) -> Outro (Twist/Ending)",
        "tone": "Casual, emotional, conversational (use 'ìŒìŠ´ì²´' or slang)",
        "pacing": "Dynamic with pauses for emphasis"
    },
    "ğŸ›ï¸ ë¦¬ë·°/í›„ê¸° (Review)": {
        "persona": "Sharp Product Reviewer",
        "max_chars": 180, # ì œí’ˆ ë³´ì—¬ì¤„ ì‹œê°„ í™•ë³´
        "structure": "Hook (Result first) -> Body (Pros & Cons) -> Outro (Final Rating)",
        "tone": "Honest, direct, trendy, critical",
        "pacing": "Moderate, focus on visuals"
    },
    "ğŸ•¯ï¸ ê°ì„±/ë™ê¸°ë¶€ì—¬ (Motivation)": {
        "persona": "Life Coach & Poet",
        "max_chars": 150, # ì—¬ë°±ì˜ ë¯¸
        "structure": "Hook (Deep Question) -> Body (Insight/Advice) -> Outro (Call to Action)",
        "tone": "Soft, warm, inspiring, calm",
        "pacing": "Slow, leaving space for music"
    }
}

# 2. BGM ë§¤í•‘: ì‚¬ìš©ìê°€ ì„ íƒí•˜ë©´ -> ë¬´ë£Œ ìŒì› URLë¡œ ë³€í™˜
# (ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ì €ì‘ê¶Œ í™•ì¸ëœ S3 ë§í¬ë‚˜ Pexels/Youtube Audio Library íŒŒì¼ ê¶Œì¥)
BGM_URLS = {
    "ğŸ”‡ ì—†ìŒ (Mute)": None,
    "â˜• Lo-fi / ì¹ í•© (Study)": "https://cdn.pixabay.com/download/audio/2022/05/27/audio_1808fbf07a.mp3",
    "ğŸŒ ì–´ì¿ ìŠ¤í‹± / ë¸Œì´ë¡œê·¸ (Daily)": "https://cdn.pixabay.com/download/audio/2022/03/24/audio_c8c8a73467.mp3", # ì„ì‹œ URL (ì‹¤ì œë¡  ë‹¤ë¥¸ íŒŒì¼ ì¶”ì²œ)
    "ğŸ¢ ì½”í¼ë ˆì´íŠ¸ / ë‰´ìŠ¤ (Info)": "https://cdn.pixabay.com/download/audio/2022/03/10/audio_c3d0b26f58.mp3",
    "ğŸ¬ ì‹œë„¤ë§ˆí‹± / ì›…ì¥í•¨ (Epic)": "https://cdn.pixabay.com/download/audio/2022/03/15/audio_736862b691.mp3",
    "ğŸ¤ª í‘í‚¤ / ì˜ˆëŠ¥ (Fun)": "https://cdn.pixabay.com/download/audio/2022/03/24/audio_823e8396d6.mp3"
}


# --- 1. í™˜ê²½ ë° UI ì„¤ì • ---
st.set_page_config(page_title="AI ì˜ìƒ ê³µì¥ (Google Edition)", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ AI ì˜ìƒ ê³µì¥ (Gemini 3 Pro Image)")

# --- [ì•ˆì „ì¥ì¹˜] Secrets ì¡°íšŒ í•¨ìˆ˜ ---
def get_secret(key_name):
    """st.secrets -> os.environ ìˆœì„œë¡œ í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        if key_name in st.secrets:
            return st.secrets[key_name]
    except (FileNotFoundError, AttributeError):
        pass
    return os.getenv(key_name)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ìŠ¤íŠœë””ì˜¤ ì„¤ì •")
    
    gemini_key = get_secret("GOOGLE_API_KEY")
    tts_key_path = get_secret("GOOGLE_APPLICATION_CREDENTIALS") # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    tts_key_json = get_secret("GOOGLE_APPLICATION_CREDENTIALS_JSON") # í´ë¼ìš°ë“œìš© JSON ë‚´ìš©
    
    
    # ìƒíƒœ í‘œì‹œ
    if gemini_key:
        st.success("âœ… Gemini API: Connected")
    else:
        st.error("âŒ Gemini API: Missing Key")
        
    if tts_key_path or tts_key_json:
        st.success("âœ… Google TTS: Connected")
    else:
        st.error("âŒ Google TTS: Missing Credentials")
        
    # [NEW] Pexels í‚¤ ì…ë ¥ ì¶”ê°€
    # secrets.tomlì— PEXELS_API_KEYê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì“°ê³ , ì—†ìœ¼ë©´ ì…ë ¥ì°½ì„ ë„ì›€
    pexels_key_env = get_secret("PEXELS_API_KEY")
    if not pexels_key_env:
        os.environ["PEXELS_API_KEY"] = st.text_input("Pexels API Key (ìŠ¤í†¡ ì˜ìƒìš©)", type="password")
    else:
        # ì´ë¯¸ í™˜ê²½ë³€ìˆ˜ì— ìˆìœ¼ë©´ ì„±ê³µ í‘œì‹œ
        st.success("âœ… Pexels API: Connected")
       
    st.divider() 
    # (ì‚¬ì´ë“œë°” ë§¨ ìœ„ìª½, ì£¼ì œ ì…ë ¥í•˜ëŠ” ê³³ ê·¼ì²˜ í˜¹ì€ ì„¤ì • ì‹œì‘ ë¶€ë¶„)
    st.header("ğŸ¬ ê¸°íš ì„¤ì •")
    
    # [NEW] ì¥ë¥´ ì„ íƒ ë©”ë‰´
    selected_genre = st.selectbox(
        "ì˜ìƒ ì¥ë¥´ (Genre)", 
        list(GENRE_SETTINGS.keys()), 
        index=0
    )
    
    # (ì„ íƒëœ ì¥ë¥´ì— ëŒ€í•œ ì„¤ëª… í‘œì‹œ - íŒ)
    st.info(f"ğŸ’¡ íŠ¹ì§•: {GENRE_SETTINGS[selected_genre]['tone']}")
    
    st.divider()    
    
    # [1] ì£¼ì¸ê³µ í˜ë¥´ì†Œë‚˜ (4ë‹¨ ì¡°ë¦½)
    st.subheader("ğŸ‘¤ ì£¼ì¸ê³µ (Persona)")
    with st.expander("ìºë¦­í„° ìƒì„¸ ì„¤ì • ì—´ê¸°", expanded=True):
        col_a, col_b = st.columns(2)
        with col_a:
            char_age_gender = st.text_input("ë‚˜ì´/ì„±ë³„/ì¸ì¢…", value="20ëŒ€ í•œêµ­ì¸ ë‚¨ì„±")
            char_outfit = st.text_input("ì˜ìƒ ìŠ¤íƒ€ì¼", value="ë„¤ì´ë¹„ ì •ì¥, íŒŒë€ ë„¥íƒ€ì´")
        with col_b:
            char_hair = st.text_input("í—¤ì–´/ì–¼êµ´ íŠ¹ì§•", value="ì§§ì€ ê²€ì€ ë¨¸ë¦¬, ì•ˆê²½")
            char_signature = st.text_input("ì‹œê·¸ë‹ˆì²˜ ì•„ì´í…œ", value="ìŠ¤ë§ˆíŠ¸ì›Œì¹˜")
            
        # ì¡°ë¦½ëœ ìºë¦­í„° ë¬˜ì‚¬ (ì´ ë³€ìˆ˜ê°€ AIì—ê²Œ ì „ë‹¬ë¨)
        character_desc = f"{char_age_gender}, {char_hair}, wearing {char_outfit}. Distinctive feature: {char_signature}"
        st.caption(f"ğŸ“ ì¡°í•© ê²°ê³¼: {character_desc}")

    # [2] í™”í’ (Dictionary í™œìš©)
    st.subheader("ğŸ¨ í™”í’ (Style)")
    selected_style_key = st.selectbox("ìŠ¤íƒ€ì¼ ì„ íƒ", list(STYLE_PROMPTS.keys()), index=2)
    video_style = STYLE_PROMPTS[selected_style_key] # ì‹¤ì œ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
    
    # [3] ì„±ìš° (ê¸°ì¡´ ìœ ì§€)
    st.subheader("ğŸ™ï¸ ì„±ìš° (Voice)")
    voice_options = {
        "ğŸ‘¨â€ğŸ’¼ ë‚¨ì„± (ì°¨ë¶„í•œ)": "ko-KR-Standard-C",
        "ğŸ‘©â€ğŸ’¼ ì—¬ì„± (ì°¨ë¶„í•œ)": "ko-KR-Standard-A",
        "ğŸ‘§ ì—¬ì„± (ë°œë„í•œ)": "ko-KR-Standard-B",
        "ğŸ‘¨ ë‚¨ì„± (ì¤‘ì €ìŒ)": "ko-KR-Standard-D"
    }
    selected_voice_label = st.selectbox("ë‚´ë ˆì´í„°", list(voice_options.keys()), index=0)
    selected_voice_name = voice_options[selected_voice_label]

    # [4] BGM (Dictionary í™œìš©)
    st.subheader("ğŸµ ë°°ê²½ìŒì•… (BGM)")
    bgm_mood = st.selectbox("ë¶„ìœ„ê¸° ì„ íƒ", list(BGM_URLS.keys()), index=1)
    
    # [NEW] ìë§‰ ON/OFF ê¸°ëŠ¥ ì¶”ê°€
    st.subheader("ğŸ“ ìë§‰ (Subtitles)")
    use_subtitles = st.checkbox("ìë§‰ í¬í•¨ (Subtitles)", value=True) # ê¸°ë³¸ê°’ì€ ì¼œì§
    
    st.divider()
    num_scenes = st.slider("ì”¬(Scene) ê°œìˆ˜", 2, 8, 4)
    

# --- 2. í•µì‹¬ ëª¨ë“ˆ í•¨ìˆ˜ ---
# [ìˆ˜ì •] genre_key ì¸ì ì¶”ê°€
def generate_script_json(topic, num_scenes, genre_key):
    """
    [Planning] ì¥ë¥´ë³„ ìµœì í™” ë¡œì§ì´ ì ìš©ëœ ê¸°íšì•ˆ ìƒì„±
    """
    if not gemini_key: return None
    
    # ì„ íƒëœ ì¥ë¥´ì˜ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    settings = GENRE_SETTINGS.get(genre_key, GENRE_SETTINGS["ğŸ“° ì •ë³´/ë‰´ìŠ¤ (Info)"])
    
    try:
        genai_old.configure(api_key=gemini_key)
        model = genai_old.GenerativeModel('gemini-2.5-flash') 
        
        prompt = f"""
        You are a {settings['persona']} specialized in creating viral YouTube Shorts.
        Create a script for the topic: '{topic}'
        
        [GENRE SPECIFIC RULES]
        - **Genre**: {genre_key}
        - **Tone**: {settings['tone']}
        - **Structure Strategy**: Follow {settings['structure']}
        - **Length Constraint**: Keep the Korean narrative STRICTLY under **{settings['max_chars']} characters** (including spaces). This is critical for video pacing.
        
        [CONSTRAINT - SCENE COUNT]
        Generate exactly {num_scenes} scenes.
        
        [LANGUAGE RULES]
        1. "narrative": **KOREAN (í•œêµ­ì–´)**. Style must match the Tone ({settings['tone']}).
        2. "visual_prompt": **KOREAN (í•œêµ­ì–´)**.
        3. **Visual Strategy**:
           - If the genre is 'Review' or 'Info', focus on showing the object/fact clearly.
           - If the genre is 'Story' or 'Motivation', focus on facial expressions and atmosphere.
           - Use `[VIDEO] keyword` for generic scenes (Sky, City, Coffee).
        
        [OUTPUT JSON FORMAT]
        {{
          "video_title": "Title in Korean",
          "scenes": [
            {{ "seq": 1, "narrative": "Korean script...", "visual_prompt": "Korean description..." }},
            ...
          ]
        }}
        """
        
        response = model.generate_content(prompt)
        text = response.text.strip()
        if text.startswith("```json"): text = text[7:]
        if text.endswith("```"): text = text[:-3]
        return json.loads(text)
        
    except Exception as e:
        st.error(f"ê¸°íš ì˜¤ë¥˜: {e}")
        return None

def generate_image_google(prompt, filename, ref_image_path=None):
    """
    [Image] Gemini 3 Pro Image: ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ë¥¼ í™œìš©í•œ ìºë¦­í„° ê³ ì •
    """
    if not gemini_key: return None
    
    output_path = os.path.join(tempfile.gettempdir(), filename)

    try:
        client = genai.Client(api_key=gemini_key)
        # ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¥¸ ìµœì‹  ëª¨ë¸ëª… (2025ë…„ ê¸°ì¤€)
        model_id = "gemini-3-pro-image-preview"

        # 1. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (í…ìŠ¤íŠ¸)
        # ìºë¦­í„° ì¼ê´€ì„±ì„ ìœ„í•´ 'Consistent character' í‚¤ì›Œë“œ ê°•ì¡°
        contents_parts = [types.Part.from_text(text=prompt + ", consistent character identity, high fidelity")]

        # 2. ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì¶”ê°€ (í•µì‹¬ ê¸°ëŠ¥)
        # ë§Œì•½ ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´, í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ AIì—ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
        if ref_image_path and os.path.exists(ref_image_path):
            with open(ref_image_path, "rb") as f:
                img_data = f.read()
                # í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ë¥¼ ë©€í‹°ëª¨ë‹¬ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
                contents_parts.append(types.Part.from_bytes(data=img_data, mime_type="image/png"))

        contents = [types.Content(role="user", parts=contents_parts)]
        
        generate_content_config = types.GenerateContentConfig(
            response_modalities=["IMAGE"],
            image_config=types.ImageConfig(image_size="1K"), # 1024x1024
        )

        response = client.models.generate_content(
            model=model_id,
            contents=contents,
            config=generate_content_config,
        )
        
        if response.candidates and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if part.inline_data and part.inline_data.data:
                    with open(output_path, "wb") as f:
                        f.write(part.inline_data.data)
                    return output_path
        
        return None

    except Exception as e:
        # Gemini 3 ëª¨ë¸ì´ ì•„ì§ ë°°í¬ë˜ì§€ ì•Šì€ ë¦¬ì „ì¼ ê²½ìš° ì•ˆì „ì¥ì¹˜
        if "404" in str(e) or "not found" in str(e).lower():
            st.warning("âš ï¸ Gemini 3 ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ 2.0 Flashë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            # (ì—¬ê¸°ì— ê¸°ì¡´ generate_image_google ë¡œì§ì˜ Fallback ì½”ë“œë¥¼ ë„£ê±°ë‚˜ ì¬ê·€ í˜¸ì¶œ ê°€ëŠ¥)
        st.warning(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def generate_audio(text, filename, voice_name="ko-KR-Standard-C"):
    """
    [Voice] Google TTS: ì„±ìš° ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€
    """
    output_path = os.path.join(tempfile.gettempdir(), filename)
    
    # ì¸ì¦ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    credentials = None
    if tts_key_json:
        try:
            creds_info = json.loads(tts_key_json, strict=False)
            credentials = service_account.Credentials.from_service_account_info(creds_info)
        except: return None
    elif tts_key_path and os.path.exists(tts_key_path):
        credentials = service_account.Credentials.from_service_account_file(tts_key_path)
    else:
        return None

    try:
        client = texttospeech.TextToSpeechClient(credentials=credentials)
        input_text = texttospeech.SynthesisInput(text=text)
        
        # [í•µì‹¬ ìˆ˜ì •] ì „ë‹¬ë°›ì€ voice_name ì ìš©
        # ì„±ë³„(Gender)ì€ ëª©ì†Œë¦¬ ì´ë¦„ì— ë§ì¶° ìë™ ì„¤ì •
        if "Standard-A" in voice_name or "Standard-B" in voice_name:
            gender = texttospeech.SsmlVoiceGender.FEMALE
        else:
            gender = texttospeech.SsmlVoiceGender.MALE
            
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR", 
            name=voice_name, 
            ssml_gender=gender
        )
        
        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
        
        response = client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)
        with open(output_path, "wb") as out:
            out.write(response.audio_content)
        return output_path
        
    except Exception as e:
        st.error(f"ğŸ™ï¸ TTS ì˜¤ë¥˜: {e}")
        return None

def apply_random_motion(clip):
    """
    [Motion] ì¤Œì¸, ì¤Œì•„ì›ƒ, ì¢Œìš°/ìƒí•˜ íŒ¨ë‹ ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.
    """
    try:
        import cv2
    except ImportError:
        return clip

    # ê°€ëŠ¥í•œ íš¨ê³¼ ëª©ë¡
    effects = ['zoom_in', 'zoom_out', 'pan_left', 'pan_right', 'pan_up', 'pan_down']
    effect_type = random.choice(effects)
    
    # íš¨ê³¼ ê°•ë„ (ë„ˆë¬´ ì–´ì§€ëŸ½ì§€ ì•Šê²Œ ì¡°ì ˆ)
    speed = 0.04  # ì›€ì§ì„ ì†ë„

    def fl(get_frame, t):
        img = get_frame(t)
        h, w = img.shape[:2]
        
        # ì‹œê°„ tì— ë”°ë¥¸ ì§„í–‰ë¥  (0.0 ~ 1.0) -> í´ë¦½ ëë‚  ë•Œ ìµœëŒ€ ì›€ì§ì„
        progress = t / clip.duration if clip.duration > 0 else 0
        scale = 1 + (speed * progress) # 1.0 ~ 1.04
        
        # ì›ë³¸ í¬ê¸° ìœ ì§€ë¥¼ ìœ„í•œ ë¦¬ì‚¬ì´ì§• ê³„ì‚°
        new_w, new_h = int(w * scale), int(h * scale)
        
        # OpenCVë¡œ ì´ë¯¸ì§€ í™•ëŒ€ (ê¸°ë³¸ ë² ì´ìŠ¤)
        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # ì˜ë¼ë‚¼ ìœ„ì¹˜(Crop) ê²°ì • ë¡œì§
        if effect_type == 'zoom_in':
            # ì¤‘ì•™ì„ í–¥í•´ ì¤Œì¸ (ì ì  ì•ˆìª½ì„ ë³´ì—¬ì¤Œ)
            x = (new_w - w) // 2
            y = (new_h - h) // 2
            
        elif effect_type == 'zoom_out':
            # ì¤Œì•„ì›ƒì€ ë°˜ëŒ€ë¡œ êµ¬í˜„ì´ ê¹Œë‹¤ë¡œìš°ë¯€ë¡œ, 
            # "ì´ë¯¸ í™•ëŒ€ëœ ìƒíƒœì—ì„œ ì‹œì‘í•´ì„œ ì›ë˜ëŒ€ë¡œ ëŒì•„ì˜¤ëŠ”" ë¡œì§ ëŒ€ì‹ 
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ "ì•½í•œ ì¤Œì¸"ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì—­ë°©í–¥ êµ¬í˜„ í•„ìš”.
            # (ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•˜ê¸° ìœ„í•´ zoom_inê³¼ ì¤Œ í¬ì¸íŠ¸ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •)
            x = (new_w - w) // 2
            y = (new_h - h) // 2
            
        elif effect_type == 'pan_left':
            # ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ ì´ë™ (ë³´ì—¬ì£¼ëŠ” ë·°í¬íŠ¸ê°€ ì™¼ìª½ìœ¼ë¡œ ê° -> xëŠ” 0ì—ì„œ ì‹œì‘í•´ì„œ ì»¤ì§?? ë°˜ëŒ€ì„)
            # ì´ë¯¸ì§€ì˜ ì˜¤ë¥¸ìª½ ëì„ ë³´ì—¬ì£¼ë‹¤ê°€ -> ì™¼ìª½ìœ¼ë¡œ ì´ë™
            # x: (new_w - w) -> 0 (ê°ì†Œ)
            max_x = new_w - w
            x = int(max_x * (1 - progress))
            y = (new_h - h) // 2 # YëŠ” ì¤‘ì•™ ê³ ì •
            
        elif effect_type == 'pan_right':
            # ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™
            # x: 0 -> (new_w - w) (ì¦ê°€)
            max_x = new_w - w
            x = int(max_x * progress)
            y = (new_h - h) // 2
            
        elif effect_type == 'pan_up':
            # ì•„ë˜ì—ì„œ ìœ„ë¡œ
            x = (new_w - w) // 2
            max_y = new_h - h
            y = int(max_y * (1 - progress))
            
        elif effect_type == 'pan_down':
            # ìœ„ì—ì„œ ì•„ë˜ë¡œ
            x = (new_w - w) // 2
            max_y = new_h - h
            y = int(max_y * progress)
            
        else:
            # ê¸°ë³¸ ì¤‘ì•™
            x, y = (new_w - w) // 2, (new_h - h) // 2

        # ì¢Œí‘œê°€ ìŒìˆ˜ê±°ë‚˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ í´ë¦¬í•‘
        x = max(0, min(x, new_w - w))
        y = max(0, min(y, new_h - h))
        
        return img_resized[y:y+h, x:x+w]

    return clip.fl(fl)

def get_bgm_path(mood_key):
    """
    ì„ íƒëœ BGM í‚¤ì— í•´ë‹¹í•˜ëŠ” URLì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    if not mood_key or mood_key == "ğŸ”‡ ì—†ìŒ (Mute)":
        return None
    
    url = BGM_URLS.get(mood_key)
    if not url: return None
    
    # [í•µì‹¬ ìˆ˜ì • 1] íŒŒì¼ëª…ì—ì„œ í•œê¸€ ì œê±° (ê´„í˜¸ ì•ˆì˜ ì˜ì–´ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ)
    # ì˜ˆ: "ğŸŒ ì–´ì¿ ìŠ¤í‹± / ë¸Œì´ë¡œê·¸ (Daily)" -> "Daily"
    try:
        if '(' in mood_key:
            english_key = mood_key.split('(')[-1].replace(')', '').strip()
        else:
            english_key = "default"
    except:
        english_key = "bgm"
        
    # ì˜ë¬¸/ìˆ«ìë§Œ ë‚¨ê¸°ê¸°
    safe_name = "".join(x for x in english_key if x.isalnum())
    filename = f"bgm_{safe_name}.mp3"
    filepath = os.path.join(tempfile.gettempdir(), filename)
    
    # ìºì‹± í™•ì¸ ë° ìœ íš¨ì„± ê²€ì‚¬
    if os.path.exists(filepath):
        # íŒŒì¼ì´ ìˆëŠ”ë° í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´(1KB ë¯¸ë§Œ) ì‚­ì œí•˜ê³  ë‹¤ì‹œ ë°›ìŒ
        if os.path.getsize(filepath) < 1000:
            os.remove(filepath)
        else:
            return filepath
        
    try:
        # [í•µì‹¬ ìˆ˜ì • 2] ë‹¤ìš´ë¡œë“œ ê²€ì¦
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            print(f"âŒ BGM ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨(Status): {mood_key}")
            return None
            
        # ë‚´ìš©ì´ HTML ì—ëŸ¬í˜ì´ì§€ì¸ì§€ í™•ì¸ (í¬ê¸° ì²´í¬)
        if len(response.content) < 1000:
            print(f"âŒ BGM íŒŒì¼ ì†ìƒ(Too small): {mood_key}")
            return None
            
        with open(filepath, "wb") as f:
            f.write(response.content)
        return filepath
    except Exception as e:
        print(f"âŒ BGM ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        return None

def get_sfx_path(sfx_name):
    """
    [ì•ˆì „ ë²„ì „] íš¨ê³¼ìŒ ë‹¤ìš´ë¡œë“œ ë° ê²€ì¦
    """
    if not sfx_name or sfx_name == "None":
        return None
        
    # 1. íš¨ê³¼ìŒ URL ë§¤í•‘ (ì ‘ê·¼ì´ ë” ì›í™œí•œ GitHub ì†ŒìŠ¤ ë“±ìœ¼ë¡œ ëŒ€ì²´ ê¶Œì¥)
    # ì•„ë˜ëŠ” ì˜ˆì‹œìš© URLì´ë©°, ì‹¤ì œ ì„œë¹„ìŠ¤ì‹œ ë³¸ì¸ì˜ S3ë‚˜ í˜¸ìŠ¤íŒ… URLì„ ë„£ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì „í•©ë‹ˆë‹¤.
    sfx_library = {
        "Whoosh (ì „í™˜)": "https://cdn.pixabay.com/download/audio/2022/03/24/audio_c8c8a73467.mp3", # Pixabay Free
        "Ding (ì •ë‹µ/ì•„ì´ë””ì–´)": "https://cdn.pixabay.com/download/audio/2022/03/15/audio_736862b691.mp3",
        "Camera (ì°°ì¹µ)": "https://cdn.pixabay.com/download/audio/2022/03/10/audio_c3d0b26f58.mp3",
        "Pop (ë“±ì¥)": "https://cdn.pixabay.com/download/audio/2022/03/10/audio_c8c8a73467.mp3", # ì„ì‹œ ëŒ€ì²´
        "Keyboard (íƒ€ì)": "https://cdn.pixabay.com/download/audio/2022/03/24/audio_823e8396d6.mp3"
    }
    
    url = sfx_library.get(sfx_name)
    if not url: return None
    
    # 2. íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜ (í•œê¸€ ì œê±°, ìˆœìˆ˜ ì˜ë¬¸/ìˆ«ìë§Œ ë‚¨ê¹€)
    # ì˜ˆ: "Pop (ë“±ì¥)" -> "Pop"
    safe_key = sfx_name.split('(')[0].strip() # ê´„í˜¸ ì•ë¶€ë¶„ë§Œ ê°€ì ¸ì˜´
    safe_name = "".join(x for x in safe_key if x.isalnum())
    filename = f"sfx_{safe_name}.mp3"
    filepath = os.path.join(tempfile.gettempdir(), filename)
    
    # 3. ìºì‹± ë° ë‹¤ìš´ë¡œë“œ ê²€ì¦
    if not os.path.exists(filepath):
        try:
            # íƒ€ì„ì•„ì›ƒ 3ì´ˆ ì„¤ì •
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=3)
            
            # (ì¤‘ìš”) ìš”ì²­ì´ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸
            if response.status_code != 200:
                print(f"âŒ íš¨ê³¼ìŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨(HTTP Error): {sfx_name}")
                return None
                
            # (ì¤‘ìš”) íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ì‘ìœ¼ë©´(1KB ë¯¸ë§Œ) ê°€ì§œ íŒŒì¼(HTML ì—ëŸ¬í˜ì´ì§€)ì¼ í™•ë¥  ë†’ìŒ
            if len(response.content) < 1000:
                print(f"âŒ íš¨ê³¼ìŒ íŒŒì¼ ì†ìƒ ì˜ì‹¬(Too small): {sfx_name}")
                return None
                
            with open(filepath, "wb") as f:
                f.write(response.content)
                
        except Exception as e:
            print(f"âŒ íš¨ê³¼ìŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
            return None
            
    return filepath

# --- (get_sfx_path í•¨ìˆ˜ ì•„ë˜ì— ì¶”ê°€) ---

def get_korean_font():
    """
    í•œê¸€ í°íŠ¸(ë‚˜ëˆ”ê³ ë”•)ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    font_path = os.path.join(tempfile.gettempdir(), "NanumGothic-Bold.ttf")
    
    # ì´ë¯¸ ìˆìœ¼ë©´ ë°˜í™˜
    if os.path.exists(font_path):
        return font_path
        
    # ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ (Google Fonts)
    url = "https://github.com/google/fonts/raw/main/ofl/nanumgothic/NanumGothic-Bold.ttf"
    try:
        response = requests.get(url, timeout=10)
        with open(font_path, "wb") as f:
            f.write(response.content)
        return font_path
    except Exception:
        return None

def create_subtitle_clip(text, duration, font_path):
    """
    [ê°œì„ ë¨] ê¸´ ë¬¸ì¥ ìë™ ì¤„ë°”ê¿ˆ + ì¤‘ì•™ ì •ë ¬ + í°íŠ¸ í¬ê¸° ìµœì í™”
    """
    try:
        w, h = 1280, 720
        # íˆ¬ëª… ìº”ë²„ìŠ¤ ìƒì„±
        img = PIL.Image.new('RGBA', (w, h), (255, 255, 255, 0))
        draw = PIL.ImageDraw.Draw(img)
        
        # 1. í°íŠ¸ ì„¤ì • (í¬ê¸°ë¥¼ 55 -> 40ìœ¼ë¡œ ì¤„ì„)
        font_size = 40 
        try:
            if font_path:
                font = PIL.ImageFont.truetype(font_path, font_size)
            else:
                font = PIL.ImageFont.load_default()
        except:
            font = PIL.ImageFont.load_default()

        # 2. ìë™ ì¤„ë°”ê¿ˆ (í•µì‹¬!)
        # í™”ë©´ í­ì— ë§ì¶°ì„œ ì•½ 30~35ê¸€ìë§ˆë‹¤ ì¤„ì„ ë°”ê¿ˆ
        wrapped_text = textwrap.fill(text, width=35)

        # 3. ê¸€ì í¬ê¸° ë° ìœ„ì¹˜ ê³„ì‚° (ì—¬ëŸ¬ ì¤„ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ multiline ì‚¬ìš©)
        # í…ìŠ¤íŠ¸ ë°•ìŠ¤ í¬ê¸° êµ¬í•˜ê¸°
        left, top, right, bottom = draw.multiline_textbbox((0, 0), wrapped_text, font=font, align="center")
        text_w = right - left
        text_h = bottom - top
        
        # ì •ì¤‘ì•™ í•˜ë‹¨ ìœ„ì¹˜ ê³„ì‚°
        x = (w - text_w) / 2
        y = h - text_h - 50 # ë°”ë‹¥ì—ì„œ 50px ìœ„ (ì—¬ìœ  ê³µê°„ í™•ë³´)

        # 4. ê·¸ë¦¬ê¸° (í…Œë‘ë¦¬ í¬í•¨)
        draw.multiline_text(
            (x, y), 
            wrapped_text, 
            font=font, 
            fill="white", 
            stroke_width=3, 
            stroke_fill="black", 
            align="center"
        )
        
        return ImageClip(np.array(img)).set_duration(duration)
        
    except Exception as e:
        print(f"ìë§‰ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# --- (create_subtitle_clip í•¨ìˆ˜ ì•„ë˜ì— ì¶”ê°€) ---

def get_pexels_video(query, duration):
    """
    [Stock Video] Pexels APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬´ë£Œ ì˜ìƒì„ ë‹¤ìš´ë¡œë“œí•˜ê³ ,
    ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ê²Œ í¸ì§‘(Loop/Cut)í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. API í‚¤ í™•ì¸ (ì‚¬ì´ë“œë°” ì…ë ¥ê°’ ë˜ëŠ” Secrets)
    api_key = get_secret("PEXELS_API_KEY") 
    if not api_key:
        st.error("âŒ Pexels API Keyê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
        
    # 2. ê²€ìƒ‰ ìš”ì²­
    headers = {'Authorization': api_key}
    # landscape(ê°€ë¡œ), medium(ì¤‘ê°„í™”ì§ˆ) ì„¤ì •ìœ¼ë¡œ ì „ì†¡ëŸ‰ ì ˆì•½
    params = {'query': query, 'per_page': 1, 'orientation': 'landscape', 'size': 'medium'}
    
    try:
        response = requests.get('https://api.pexels.com/videos/search', headers=headers, params=params, timeout=10)
        data = response.json()
        
        if not data.get('videos'):
            return None # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
            
        # 3. ì˜ìƒ URL ì¶”ì¶œ (ê°€ì¥ ì ë‹¹í•œ í™”ì§ˆ ì„ íƒ)
        video_files = data['videos'][0]['video_files']
        # ë„ˆë¹„ê°€ 1280ì— ê°€ê¹Œìš´ íŒŒì¼ ì°¾ê¸° (HDê¸‰)
        target_video = min(video_files, key=lambda x: abs(x['width'] - 1280))
        video_url = target_video['link']
        
        # 4. ë‹¤ìš´ë¡œë“œ ë° ìºì‹±
        safe_name = "".join(x for x in query if x.isalnum())
        filename = f"pexels_{safe_name}.mp4"
        filepath = os.path.join(tempfile.gettempdir(), filename)
        
        if not os.path.exists(filepath):
            vid_response = requests.get(video_url, stream=True)
            with open(filepath, 'wb') as f:
                for chunk in vid_response.iter_content(chunk_size=1024):
                    if chunk: f.write(chunk)
                    
        # 5. MoviePy í´ë¦½ ë³€í™˜ ë° ê¸¸ì´ ë§ì¶¤
        clip = VideoFileClip(filepath)
        
        # ì†Œë¦¬ ì œê±° (TTSì™€ ê²¹ì¹˜ë¯€ë¡œ)
        clip = clip.without_audio()
        
        # ê¸¸ì´ ë§ì¶”ê¸° ë¡œì§
        if clip.duration < duration:
            # ì˜ìƒì´ ì§§ìœ¼ë©´ ë°˜ë³µ(Loop)
            # vfx.loopëŠ” ìµœì‹  ë²„ì „ì—ì„œ ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì•ˆì „í•˜ê²Œ ìˆ˜ë™ ë°˜ë³µ
            loop_count = int(duration // clip.duration) + 2
            clip = concatenate_videoclips([clip] * loop_count)
            
        # í•„ìš”í•œ ê¸¸ì´ë§Œí¼ ìë¥´ê¸°
        clip = clip.subclip(0, duration)
        
        # 720pë¡œ ë¦¬ì‚¬ì´ì§•
        clip = clip.resize(height=720)
        
        # ë§Œì•½ ë¹„ìœ¨ì´ ì•ˆ ë§ìœ¼ë©´ ì¤‘ì•™ í¬ë¡­ (16:9 ê°•ì œ)
        # (ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•˜ê¸° ìœ„í•´ resizeë§Œ ì ìš©, í•„ìš”ì‹œ crop ì¶”ê°€ ê°€ëŠ¥)
        
        return clip

    except Exception as e:
        print(f"Pexels ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def generate_video_veo(prompt, filename):
    """
    [NEW] Google Veo (Text-to-Video)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not gemini_key: return None
    
    output_path = os.path.join(tempfile.gettempdir(), filename)
    
    # ì´ë¯¸ ìƒì„±ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ìºì‹œ ì‚¬ìš© (VeoëŠ” ë¹„ì‹¸ê³  ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ)
    if os.path.exists(output_path):
        return output_path

    try:
        client = genai.Client(api_key=gemini_key)
        
        # [ì¤‘ìš”] 2025ë…„ 12ì›” ê¸°ì¤€ ìµœì‹  ëª¨ë¸ ID (ìƒí™©ì— ë”°ë¼ 'veo-3.1-generate-preview-1015' ë“±ìœ¼ë¡œ ë³€ê²½ í•„ìš”)
        model_id = "veo-3.1-generate-preview" 

        # ì˜ìƒ ìƒì„± ì„¤ì •
        # 24fps, 1080p ë“± ì„¤ì • ê°€ëŠ¥
        generate_config = types.GenerateContentConfig(
            response_modalities=["VIDEO"], # ì‘ë‹µ í˜•ì‹ì„ ë¹„ë””ì˜¤ë¡œ ì„¤ì •
            video_config=types.VideoConfig(
                aspect_ratio="16:9", 
                sample_count=1, 
                seconds=6 # ì”¬ë‹¹ 6ì´ˆ ìƒì„±
            )
        )

        prompt_text = f"Cinematic movie shot, {prompt}, high quality, 4k"

        # ìƒì„± ìš”ì²­ (ì‹œê°„ì´ 30ì´ˆ~1ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŒ)
        response = client.models.generate_content(
            model=model_id,
            contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt_text)])],
            config=generate_config
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        if response.candidates and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if part.inline_data: # ë¹„ë””ì˜¤ ë°ì´í„°ê°€ ì¸ë¼ì¸ìœ¼ë¡œ ì˜¤ëŠ” ê²½ìš°
                    with open(output_path, "wb") as f:
                        f.write(part.inline_data.data)
                    return output_path
                elif part.file_data: # íŒŒì¼ URIë¡œ ì˜¤ëŠ” ê²½ìš° (Vertex AI ë“±)
                    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë¡œì§ í•„ìš” (SDK ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„. ì—¬ê¸°ì„  ì¸ë¼ì¸ ê°€ì •)
                    pass
        
        return None

    except Exception as e:
        print(f"Veo ìƒì„± ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ Noneì„ ë°˜í™˜í•˜ì—¬ ê¸°ì¡´ AI ì´ë¯¸ì§€(ë°±ì—…)ë¡œ ë„˜ì–´ê°€ê²Œ í•¨
        return None
    
def create_subtitle(text, duration, font_path):
    """
    [ë¬´ì„¤ì¹˜ ë²„ì „] Pillowë¥¼ ì‚¬ìš©í•˜ì—¬ ìë§‰ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ImageMagickì´ í•„ìš” ì—†ì–´ ì˜¤ë¥˜ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        # 1. ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì • (HD í•´ìƒë„ ê¸°ì¤€)
        w, h = 1280, 720
        # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± (RGBA)
        img = Image.new('RGBA', (w, h), (255, 255, 255, 0))
        draw = ImageDraw.Draw(img)
        
        # 2. í°íŠ¸ ë¡œë“œ
        font_size = 50
        try:
            if font_path:
                font = ImageFont.truetype(font_path, font_size)
            else:
                # í°íŠ¸ ê²½ë¡œ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ (í•œê¸€ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ)
                font = ImageFont.load_default()
        except Exception:
            font = ImageFont.load_default()

        # 3. í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (ê°„ë‹¨ ë²„ì „)
        if len(text) > 25:
            text = text[:25] + "\n" + text[25:]
        
        # 4. í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚° ë° ìœ„ì¹˜ ì¡ê¸° (ì¤‘ì•™ í•˜ë‹¨)
        # textbboxëŠ” Pillow ìµœì‹  ë²„ì „ ê¸°ì¤€
        left, top, right, bottom = draw.textbbox((0, 0), text, font=font)
        text_w = right - left
        text_h = bottom - top
        
        x = (w - text_w) / 2
        y = h - 100 # ë°‘ì—ì„œ 100px ìœ„
        
        # 5. ê¸€ì í…Œë‘ë¦¬(Stroke) ê·¸ë¦¬ê¸° (ê²€ì€ìƒ‰)
        stroke_width = 3
        draw.text((x, y), text, font=font, fill="white", stroke_width=stroke_width, stroke_fill="black")

        # 6. MoviePy í´ë¦½ìœ¼ë¡œ ë³€í™˜
        # Pillow ì´ë¯¸ì§€ -> Numpy ë°°ì—´ -> ImageClip
        return ImageClip(np.array(img)).set_duration(duration)

    except Exception as e:
        st.error(f"ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# --- 3. ë©”ì¸ ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ìƒˆë¡œê³ ì¹¨ í•´ë„ ë°ì´í„° ìœ ì§€)
if "script_data" not in st.session_state:
    st.session_state["script_data"] = None
if "step" not in st.session_state:
    st.session_state["step"] = 1

st.divider()
st.header("Step 1. ê¸°íšì•ˆ ì‘ì„±")
topic = st.text_input("ì˜ìƒ ì£¼ì œ (Topic)", placeholder="ì˜ˆ: ì§‘ì—ì„œ ë§Œë“œëŠ” ìŠ¤íƒ€ë²…ìŠ¤ ëŒì²´ë¼ë–¼ ë ˆì‹œí”¼")

# [ë²„íŠ¼ 1] ê¸°íšì•ˆ ìƒì„±
if st.button("ğŸ’¡ 1. ê¸°íšì•ˆ(ëŒ€ë³¸) ìƒì„±í•˜ê¸°", type="primary", use_container_width=True):
    if not topic:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
        
    with st.spinner("ğŸ§  Geminiê°€ ê¸°ìŠ¹ì „ê²°(Hook-Body-CTA) êµ¬ì¡°ë¡œ ê¸°íš ì¤‘ì…ë‹ˆë‹¤..."):
        # 1ë‹¨ê³„ì—ì„œ ë§Œë“  êµ¬ì¡°í™”ëœ í•¨ìˆ˜ í˜¸ì¶œ
        script_data = generate_script_json(topic, num_scenes, selected_genre)
        
        if script_data:
            st.session_state['script_data'] = script_data
            st.rerun()
        else:
            st.error("ê¸°íšì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# [UI] ëŒ€ë³¸ ìˆ˜ì • ë° í™•ì • ë‹¨ê³„
if st.session_state["step"] >= 2 and st.session_state["script_data"]:
    st.divider()
    st.header("Step 2. ëŒ€ë³¸ ë° ì—°ì¶œ ìˆ˜ì •")
    st.info("ğŸ’¡ ê¿€íŒ: 'ê·¸ë¦¼ ë¬˜ì‚¬' ì¹¸ì— ` || ` ê¸°í˜¸ë¥¼ ë„£ìœ¼ë©´ ì»·ì´ ìª¼ê°œì§‘ë‹ˆë‹¤. (ì˜ˆ: ë‚¨ìì˜ ì–¼êµ´ || ë†€ë¼ëŠ” í‘œì •)")

    data = st.session_state["script_data"]
    scenes = data.get("scenes", [])
    
    # í¼(Form)ì„ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ë°ì´í„° ìˆ˜ì§‘
    with st.form("script_edit_form"):
        # íƒ€ì´í‹€ ìˆ˜ì •
        new_title = st.text_input("ì˜ìƒ ì œëª©", value=data.get("video_title", ""))
        
        edited_scenes = []
        for i, scene in enumerate(scenes):
            st.subheader(f"ğŸ¬ Scene {scene['seq']} ({scene.get('section', 'General')})")
            
            # ë ˆì´ì•„ì›ƒ 2ë‹¨ ë¶„ë¦¬ (ì™¼ìª½: ëŒ€ë³¸ / ì˜¤ë¥¸ìª½: ê·¸ë¦¼ ë¬˜ì‚¬)
            col1, col2 = st.columns(2)
            
            with col1:
                # keyë¥¼ ê³ ìœ í•˜ê²Œ ì§€ì •í•´ì•¼ í•¨
                new_narrative = st.text_area(
                    label="ğŸ—£ï¸ ë‚´ë ˆì´ì…˜ (í•œêµ­ì–´)", 
                    value=scene['narrative'], 
                    height=100,
                    key=f"narr_area_{i}"
                )
                # íš¨ê³¼ìŒ ì„ íƒ ë©”ë‰´ ì¶”ê°€
                sfx_options = ["None", "Whoosh (ì „í™˜)", "Ding (ì •ë‹µ/ì•„ì´ë””ì–´)", "Camera (ì°°ì¹µ)", "Pop (ë“±ì¥)", "Keyboard (íƒ€ì)"]
                
                # ê¸°íšì•ˆì— ìˆëŠ” ê°’ ì°¾ê¸° (ì—†ìœ¼ë©´ None)
                current_sfx = scene.get('sound_effect', 'None')
                if current_sfx not in sfx_options: current_sfx = "None"
                
                st.selectbox(
                    "ğŸ”Š íš¨ê³¼ìŒ ì„ íƒ", 
                    sfx_options, 
                    index=sfx_options.index(current_sfx),
                    key=f"sfx_select_{i}"
                )
            
            with col2:
                new_visual = st.text_area(
                    label="ğŸ–¼ï¸ ê·¸ë¦¼ ë¬˜ì‚¬ (ì˜ì–´ ê¶Œì¥)", 
                    value=scene['visual_prompt'], 
                    height=100,
                    key=f"vis_area_{i}"
                )
            
            # ìˆ˜ì •ëœ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì„ ì¤€ë¹„ (ì‹¤ì œ ì—…ë°ì´íŠ¸ëŠ” ë²„íŠ¼ í´ë¦­ ì‹œ ì²˜ë¦¬)
            # ì—¬ê¸°ì„œëŠ” í¼ ë‚´ë¶€ë¼ UIë§Œ ë³´ì—¬ì£¼ê³ , ë°ì´í„° ì²˜ë¦¬ëŠ” ì•„ë˜ submit ë²„íŠ¼ ì´í›„ì— í•¨.
            
        # [ë²„íŠ¼ 2] ì˜ìƒ ìƒì„± ì‹œì‘
        generate_btn = st.form_submit_button("ğŸ¬ 2. ì´ ë‚´ìš©ìœ¼ë¡œ ì˜ìƒ ë§Œë“¤ê¸° (Start Generation)", type="primary", use_container_width=True)

    # í¼ ì œì¶œ ë²„íŠ¼ì´ ëˆŒë ¸ì„ ë•Œ ì‹¤í–‰
    if generate_btn:
        # ìˆ˜ì •ëœ ë°ì´í„° ìˆ˜ì§‘
        final_scenes = []
        for i, org_scene in enumerate(scenes):
            final_scenes.append({
                "seq": org_scene['seq'],
                "narrative": st.session_state[f"narr_area_{i}"],
                "visual_prompt": st.session_state[f"vis_area_{i}"],
                "sound_effect": st.session_state[f"sfx_select_{i}"] # <--- ì¶”ê°€
            })
            
        # ë³¸ê²©ì ì¸ ìƒì„± ì‹œì‘
        status_box = st.status("ğŸ—ï¸ ì˜ìƒ ì œì‘ ê³µì¥ ê°€ë™ ì¤‘...", expanded=True)
        
        # --- Phase 2: Veo + Stock Video + AI Image í•˜ì´ë¸Œë¦¬ë“œ ---
        status_box.write("ğŸ¨ Phase 2: ìºë¦­í„° ê¸°ì¤€ ì´ë¯¸ì§€(Anchor) ìƒì„± ì¤‘...")
        # [Step 0] ê¸°ì¤€ ìºë¦­í„° ì´ë¯¸ì§€ ìƒì„± (ì´ ì´ë¯¸ì§€ê°€ ì˜ìƒ ë‚´ë‚´ ì“°ì„)
        # ê°€ì¥ ìì„¸í•œ ë¬˜ì‚¬ + ì •ë©´ ì–¼êµ´ ìœ„ì£¼
        anchor_prompt = f"A detailed character sheet of {character_desc}, {video_style}, neutral expression, front view, white background"
        anchor_img_name = f"anchor_char_{int(time.time())}.png"
        
        # ì²« ë²ˆì§¸ ìƒì„± ì‹œì—ëŠ” ë ˆí¼ëŸ°ìŠ¤ê°€ ì—†ìœ¼ë¯€ë¡œ None
        anchor_image_path = generate_image_google(anchor_prompt, anchor_img_name, ref_image_path=None)
        
        if anchor_image_path:
            st.image(anchor_image_path, caption="âœ… ìƒì„±ëœ ê¸°ì¤€ ìºë¦­í„° (ì´ ì–¼êµ´ë¡œ ê³ ì •ë©ë‹ˆë‹¤)", width=200)
        else:
            st.warning("ê¸°ì¤€ ìºë¦­í„° ìƒì„± ì‹¤íŒ¨. ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        progress_bar = st.progress(0)
        generated_clips = []
        
        korean_font_path = get_korean_font()
        
        for i, scene in enumerate(final_scenes):
            idx = scene['seq']
            status_box.write(f"  - Scene {idx} ì‘ì—… ì¤‘...")
            
            timestamp = int(time.time())
            aud_name = f"aud_{idx}_{timestamp}.mp3"
            
            # 1. ì˜¤ë””ì˜¤ ìƒì„±
            aud_path = generate_audio(scene['narrative'], aud_name, voice_name=selected_voice_name)
            if not aud_path: continue
            audio_clip = AudioFileClip(aud_path)
            
            # íš¨ê³¼ìŒ ë¯¹ì‹±
            sfx_name = scene.get('sound_effect')
            sfx_path = get_sfx_path(sfx_name)
            if sfx_path and os.path.exists(sfx_path):
                try:
                    sfx_clip = AudioFileClip(sfx_path).volumex(0.6)
                    audio_clip = CompositeAudioClip([audio_clip, sfx_clip])
                except: pass
            
            scene_duration = audio_clip.duration
            visual_prompt = scene['visual_prompt'].strip()
            scene_final_clip = None

            # ==========================================
            # [ì „ëµ 1] ìŠ¤í†¡ ë¹„ë””ì˜¤ (íƒœê·¸ê°€ ìˆëŠ” ê²½ìš° ìµœìš°ì„ )
            # ==========================================
            if visual_prompt.upper().startswith("[VIDEO]"):
                search_query = visual_prompt[7:].strip()
                status_box.write(f"    ğŸ¥ ìŠ¤í†¡ ë¹„ë””ì˜¤ ê²€ìƒ‰: {search_query}")
                scene_final_clip = get_pexels_video(search_query, scene_duration)
                
                if not scene_final_clip:
                    status_box.warning("ìŠ¤í†¡ ë¹„ë””ì˜¤ ì‹¤íŒ¨ -> Veo ìƒì„± ì‹œë„")
                    visual_prompt = search_query # íƒœê·¸ ë–¼ê³  Veoë¡œ ë„˜ê¹€

            # ==========================================
            # [ì „ëµ 2] Google Veo (ì§„ì§œ ìƒì„±í˜• ë¹„ë””ì˜¤)
            # ==========================================
            if scene_final_clip is None:
                # ìºë¦­í„° ì¼ê´€ì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì¡°í•©
                veo_prompt = f"{character_desc}, {visual_prompt}, {video_style}, consistent character"
                vid_name = f"veo_{idx}_{timestamp}.mp4"
                
                status_box.write(f"    ğŸ¬ Veo ì˜ìƒ ìƒì„± ì¤‘... (ì•½ 30ì´ˆ ì†Œìš”)")
                veo_path = generate_video_veo(veo_prompt, vid_name)
                
                if veo_path:
                    try:
                        # Veo ì˜ìƒ ë¡œë“œ
                        veo_clip = VideoFileClip(veo_path)
                        # ì†Œë¦¬ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±° (TTS ì‚¬ìš© ìœ„í•´)
                        veo_clip = veo_clip.without_audio()
                        
                        # ê¸¸ì´ ë§ì¶”ê¸° (Loop or Cut)
                        if veo_clip.duration < scene_duration:
                             loop_count = int(scene_duration // veo_clip.duration) + 2
                             veo_clip = concatenate_videoclips([veo_clip] * loop_count)
                        
                        scene_final_clip = veo_clip.subclip(0, scene_duration).resize(height=720)
                        status_box.write("    âœ… Veo ìƒì„± ì„±ê³µ!")
                    except Exception as e:
                        st.warning(f"Veo í´ë¦½ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

            # ==========================================
            # [ì „ëµ 3] AI ì´ë¯¸ì§€ (Veo ì‹¤íŒ¨ ì‹œ ë°±ì—…)
            # ==========================================
            if scene_final_clip is None:
                status_box.write("    ğŸ¨ AI ì´ë¯¸ì§€ ëª¨ë“œ (ë°±ì—…) ì‹¤í–‰")
                # (ê¸°ì¡´ ì´ë¯¸ì§€ ì»· ìª¼ê°œê¸° ë¡œì§ ìœ ì§€)
                raw_prompts = visual_prompt.split('||')
                valid_prompts = [p.strip() for p in raw_prompts if p.strip()]
                if not valid_prompts: valid_prompts = [visual_prompt]
                
                clip_duration = scene_duration / len(valid_prompts)
                scene_sub_clips = []
                
                for sub_idx, raw_text in enumerate(valid_prompts):
                    final_prompt = f"{character_desc}, {raw_text}, {video_style}"
                    img_name = f"img_{idx}_{sub_idx}_{timestamp}.png"
                    
                    # [í•µì‹¬] ì—¬ê¸°ì„œ anchor_image_pathë¥¼ ë„˜ê²¨ì¤ë‹ˆë‹¤!
                    img_path = generate_image_google(final_prompt, img_name, ref_image_path=anchor_image_path)
                    
                    if img_path:
                        try:
                            sub_clip = ImageClip(img_path).set_duration(clip_duration).resize(height=720)
                            sub_clip = apply_random_motion(sub_clip)
                            scene_sub_clips.append(sub_clip)
                        except: pass
                
                if scene_sub_clips:
                    scene_final_clip = concatenate_videoclips(scene_sub_clips, method="compose")

            # ìµœì¢… í•©ì„± (ì˜¤ë””ì˜¤ + ìë§‰ + íŠ¸ëœì§€ì…˜)
            if scene_final_clip:
                try:
                    scene_final_clip = scene_final_clip.set_audio(audio_clip)
                    
                    if use_subtitles:
                        subtitle_clip = create_subtitle_clip(scene['narrative'], scene_final_clip.duration, korean_font_path)
                        if subtitle_clip:
                            scene_final_clip = CompositeVideoClip([scene_final_clip, subtitle_clip])
                    
                    scene_final_clip = scene_final_clip.fadein(0.5)
                    generated_clips.append(scene_final_clip)
                except Exception as e:
                    st.error(f"ìµœì¢… í•©ì„± ì‹¤íŒ¨: {e}")
            
            progress_bar.progress((i + 1) / len(final_scenes))

        # Phase 3: Final Rendering (BGM Mixing ì¶”ê°€)
        if generated_clips:
            status_box.write("ğŸ¬ Phase 3: ì˜ìƒ í•©ì¹˜ê¸° ë° BGM ë¯¹ì‹± ì¤‘...")
            try:
                # 1. ì»· í¸ì§‘ëœ ì˜ìƒ ì—°ê²°
                final_video = concatenate_videoclips(generated_clips, method="compose")
                
                # 2. BGM ì²˜ë¦¬ ë¡œì§
                bgm_path = get_bgm_path(bgm_mood)
                
                if bgm_path:
                    try:
                        # BGM ë¡œë“œ
                        bgm_clip = AudioFileClip(bgm_path)
                        
                        # ì˜ìƒ ê¸¸ì´ì— ë§ì¶° BGM ë°˜ë³µ(Loop) ë˜ëŠ” ìë¥´ê¸°
                        # (ì˜ìƒë³´ë‹¤ BGMì´ ì§§ìœ¼ë©´ ë°˜ë³µ, ê¸¸ë©´ ìë¦„)
                        if bgm_clip.duration < final_video.duration:
                            # ì§ìˆ˜ ë²ˆ ë°˜ë³µí•´ì„œ ì¶©ë¶„íˆ ê¸¸ê²Œ ë§Œë“¦
                            loop_count = int(final_video.duration // bgm_clip.duration) + 2
                            bgm_clip = concatenate_audioclips([bgm_clip] * loop_count)
                        
                        bgm_clip = bgm_clip.set_duration(final_video.duration)
                        
                        # ë³¼ë¥¨ ì¡°ì ˆ (ê°€ì¥ ì¤‘ìš”!)
                        # ëª©ì†Œë¦¬(Voice)ëŠ” 100%, BGMì€ 10%~15% ìˆ˜ì¤€ìœ¼ë¡œ ë‚®ì¶¤
                        voice_clip = final_video.audio.volumex(1.0) # ì›ë³¸ ëª©ì†Œë¦¬ ìœ ì§€
                        bgm_clip = bgm_clip.volumex(0.15)           # ë°°ê²½ìŒì•… 15% (ì€ì€í•˜ê²Œ)
                        
                        # í˜ì´ë“œ ì•„ì›ƒ (ëë‚  ë•Œ 2ì´ˆê°„ ì„œì„œíˆ ì‘ì•„ì§)
                        bgm_clip = bgm_clip.audio_fadeout(2)
                        
                        # ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° (ëª©ì†Œë¦¬ + BGM)
                        final_audio = CompositeAudioClip([voice_clip, bgm_clip])
                        final_video = final_video.set_audio(final_audio)
                        
                    except Exception as e:
                        st.warning(f"BGM í•©ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ(ì˜ìƒì€ BGM ì—†ì´ ìƒì„±ë©ë‹ˆë‹¤): {e}")

                # 3. ìµœì¢… ë‚´ë³´ë‚´ê¸°
                safe_title = "".join([c for c in new_title if c.isalnum()]).strip() or "output"
                output_path = os.path.join(tempfile.gettempdir(), f"{safe_title}_final.mp4")
                
                final_video.write_videofile(output_path, fps=24, codec='libx264', audio_codec='aac', preset='ultrafast')
                
                status_box.update(label="âœ… ì˜ìƒ ì™„ì„±!", state="complete", expanded=False)
                st.balloons()
                st.success(f"ğŸ‰ '{new_title}' ì˜ìƒì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! (BGM: {bgm_mood})")
                st.video(output_path)
                
            except Exception as e:
                st.error(f"ë Œë”ë§ ì˜¤ë¥˜: {e}")